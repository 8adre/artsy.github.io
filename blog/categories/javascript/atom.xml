<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: javascript | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/javascript/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2016-09-16T17:36:27+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Helping the Web Towards OSS by Default]]></title>
    <link href="http://artsy.github.io/blog/2016/09/06/Milestone-on-OSS-by-Default/"/>
    <updated>2016-09-06T12:17:00+00:00</updated>
    <id>http://artsy.github.io/blog/2016/09/06/Milestone-on-OSS-by-Default</id>
    <content type="html"><![CDATA[<p>The main Artsy.net website for the desktop, <a href="https://github.com/artsy/force">Force</a>, was our first Artsy application to open its source code, <a href="http://artsy.github.io/author/craig">Craig</a> and <a href="http://artsy.github.io/author/brennan">Brennan</a> did it <a href="/blog/2014/09/05/we-open-sourced-our-isomorphic-javascript-website/">back in 2014</a>. Force's public offering laid the groundwork for the iOS OSS projects to come afterwards: <a href="/blog/2014/11/13/eidolon-retrospective/">Eidolon</a>, <a href="/blog/2015/04/28/how-we-open-sourced-eigen/">Eigen</a>, <a href="/blog/2015/08/06/open-sourcing-energy/">Energy</a> and <a href="/blog/2015/11/05/Emergence-Code-Review/">Emergence</a>.</p>

<p>Though Force wasn't quite Open Source by Default, it represented a <em>really</em> important step for  Artsy's OSS perspective but was not the end goal. We were opening our source, but not opening our process.</p>

<p>This month both <a href="https://github.com/artsy/force">Force</a>, the desktop version of <a href="https://www.artsy.net/">Artsy.net</a> and <a href="https://github.com/artsy/microgravity">Microgravity</a>, the mobile version - moved to being built entirely in the open. Read on to find out how.</p>

<!-- more -->


<h2>Force</h2>

<p>Over the course of the last month, I've sat on and off with Charles "<a href="http://charlesbroskoski.com/_/">Cab</a>" Broskoski, and figured out what it would take to migrate Force to work in the public. Previous to this, work happened on a private repo, and we would push that code to the public.</p>

<p>We scoped out what it would require, creating an issue that summarized the work. Then we waited for 2 weeks, to give people the chance to discuss the idea and to offer examples for why we should delay or not move. Not all projects <em>should</em> be OSS, and everyone should have a say when it affects them - giving some time let the team speak their mind. Especially during summer, when people were less active at work.</p>

<p></div></div><a href='/images/oss-milestone/force-oss.png'><img src="/images/oss-milestone/force-oss.png"></a><div class='meta-container'><header>&nbsp;</header></div><div class='date-container'>&nbsp;</div><div class='content-container'><div class='entry-content'></p>

<p>It had been 9 months since the last commit to the public repo, and so auditing the commits was a matter of investigating into configuration files, and seeing what's changed since the last public commit.</p>

<p>Next up, we renamed the current <code>force</code> repo to <code>force-private</code>. This was to keep the old issues and PRs around after we moved to working in the public. With <code>force</code> now available we re-named the already public project.</p>

<p>We then ensured all outstanding PRs were merged or closed, and pushed the commits from <code>force-private</code> to the now OSS <code>force</code>.</p>

<h3>CI</h3>

<p>To get back up to speed we needed to set up CI, figuring this out took time.</p>

<p>We got testing up and running in no time. However, Force is deployed via <a href="https://semaphoreci.com/">Semaphore CI</a>, and to deploy we needed to push compiled assets to S3. To pull that off, we needed access to an S3 key, and token.</p>

<p>In our iOS projects, <a href="https://github.com/artsy/eidolon/pull/607">we do not expose environment variables</a> to PRs from forks, so we don't expect them to pass from external contributors. This is fine, because we have <a href="http://artsy.github.io/blog/2016/01/13/OSS-Expectations/">different expectations</a> for OSS apps vs libraries. We do this to ensure that we don't receive a PR that adds <code>printenv</code> to the CI scripts, exposing our secret keys.</p>

<p>As we couldn't add the keys to our testing environment, we added them to our heroku environment then took them from that. Semaphore sets up our heroku environment only during deployment, so in the deployment phase, we can use a line like:</p>

<pre><code class="sh">export FORCE_S3_KEY=$(heroku config:get FORCE_S3_KEY --app force-production)
</code></pre>

<p>This sets up the environment like we used to have it when force was private.</p>

<h3>Team</h3>

<p>We needed to move all the team members to using the OSS version of our apps. This is a little bit complicated as <a href="/blog/2012/01/29/how-art-dot-sy-uses-github-to-build-art-dot-sy/">we work from forks</a>. <a href="http://www.anandarooproy.com/portfolio">Roop</a>, an engineer on the web team, created a "Force OSS Dance Script" ( sidenote: <a href="http://www.anandarooproy.com/portfolio">his site</a> is worth a visit, there's 15 years of interesting maps. )</p>

<pre><code class="sh">## RENAME THE OLD REPO

# on GitHub

# - Go to my fork https://github.com/&lt;username&gt;/force
# - Go to Settings tab
# - Rename repo to "force-private"

# on my local machine

mv force force-private
cd force-private
git remote set-url upstream git@github.com:artsy/force-private.git
git remote set-url origin git@github.com:&lt;username&gt;/force-private.git


## FORK AND CLONE THE NEW REPO

# back to GitHub

# - Go to the new Force repo https://github.com/artsy/force
# - Fork it to my account

# back to my local machine

git clone git@github.com:&lt;username&gt;/force.git
cd force
git remote add upstream git@github.com:artsy/force.git
cp ../force-private/.env ./
cp ../force-private/node_modules ./ # or just 'npm install' again


# all good now - both repos on local machine with correct remotes, envs, deps
</code></pre>

<p>For Force, all the same commits existed in both repos, so it would be difficult to push secrets to the open repo by accident. However, individuals did to sync up a new version of their forks.</p>

<p>And that, is how we moved force into OSS by Default. :+1: - We'll cover the issues migration later.</p>

<h2>Microgravity</h2>

<p>I have a lot of love for Microgravity. It's the web project that made <a href="/blog/2015/04/28/how-we-open-sourced-eigen/">Eigen</a> possible. Once Force had moved, I started spending time with Craig trying to understand what it would take to open up Microgravity.</p>

<p></div></div><a href='/images/oss-milestone/micrograv-oss.png'><img src="/images/oss-milestone/micrograv-oss.png"></a><div class='meta-container'><header>&nbsp;</header></div><div class='date-container'>&nbsp;</div><div class='content-container'><div class='entry-content'></p>

<p>It is no surprise to find a lot of overlap, both projects are based on the same foundations: <a href="http://ezeljs.com">Ezel.js</a>.</p>

<p>We didn't trust the commit history for microgravity, so we nuked it. Same as our native OSS apps.</p>

<p>We came up with a pattern to make it easier for people to migrate issues, we created a <code>migrate</code> GitHub label that anyone can apply to an issue in a private repo. Then we use <a href="https://github-issue-mover.appspot.com">Issue Mover for GitHub</a> with some inline JavaScript to loop through all our issues to migrate. As it's applying a label we can ask product owners and designers to choose ones that are important to them too.</p>

<p>--</p>

<p>I love that I got to help make these changes, the web team started the process of opening our apps at Artsy, then the mobile team took the next big step. Now the teams are both in lock-step, and if you work on the front-end at Artsy - OSS by Default is the way we all work now.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Tech Behind Live Auction Integration]]></title>
    <link href="http://artsy.github.io/blog/2016/08/09/the-tech-behind-live-auction-integration/"/>
    <updated>2016-08-09T11:30:00+00:00</updated>
    <id>http://artsy.github.io/blog/2016/08/09/the-tech-behind-live-auction-integration</id>
    <content type="html"><![CDATA[<p>In late June, the <a href="https://www.artsy.net/auctions/">Artsy auctions</a> team launched our Live Auction Integration (LAI) product. It allows people to participate online in live sales held at auction houses <a href="https://www.artsy.net/auction-partnerships">that partner with Artsy</a>. It was a big project, begun in December, involving both brand new software and extensive integration work with the rest of our systems. This is the first in what will be a series of blog posts discussing the engineering work we did to get a complex product from inception to launch in such a brief time window, with a go-live deadline set in stone weeks in advance. In this, I’ll dig into what we shipped on a high level, as well as some of the overarching technical decisions.</p>

<!-- more -->


<p>LAI raised challenges that were novel to our engineering team. The product is a real-time experience from the perspectives of the bidder and the auction house. Producing that experience requires a complex human + computer system. There are two main flows of information: from auction house to bidder, and vice versa. These are mediated by our systems and staff as follows:</p>

<ul>
<li>As bids occur in the auction house sale room, an Artsy operator working on-site inputs that activity into a web interface so that online participants can keep track of what’s happening.</li>
<li>As online participants place bids, our system records those as “prospective bids”, and an Artsy bidding clerk on site at the auction house bids on their behalf in the auction house. As those bids are recognized, they are reflected back to all participants, through the prior flow.</li>
</ul>


<p>To make this easier to visualize:</p>

<p><img src="/images/2016-08-09-the-tech-behind-live-auction-integration/Artsy%20Live%20Auction%20Integration%20flow.png" alt="Artsy Live Auction Integration Flow" /></p>

<p>This needs to happen in a tight loop to allow online bidders to be competitive with those in the room and via auction house phone clerks. The architecture and UX of the LAI product were optimized for that goal. In addition, we built the system to integrate with live events hosted by our partners. As the events are outside our direct control, there are many, many ways things can deviate from this idealized flow. We had to carefully account for these situations.</p>

<p>Where possible, we leveraged our existing auctions technology. But we took the opportunity to upgrade that technology in some places and chose new approaches in others. Meanwhile, we were running the busiest Artsy auction season to date, and we had to ensure that we weren’t disrupting our existing stack. Below, I discuss the pieces of the end-to-end product.</p>

<h1>The Live user experience</h1>

<p>When the live auction actually begins, participants and Artsy staff interact with the system with front-end software developed from scratch. Web users (desktop and mobile) and staff use a new, dedicated Artsy Live web application, which is implemented in a project we call Prediction. iOS Artsy App users can also participate with newly developed UX within that app.</p>

<h2>The web app: Prediction</h2>

<p>Our bidder and operator web interfaces are implemented in an application we call Prediction, a <a href="https://medium.com/@mjackson/universal-javascript-4761051b7ae9#.ev1yd3juy">universal</a> <a href="https://facebook.github.io/react/">React</a>+<a href="http://redux.js.org/">Redux</a> Javascript app, served from an <a href="http://expressjs.com/">Express</a> server. Using React allowed us to completely share our view layer code for prerendering in the server and making updates in the client.</p>

<p><img src="/images/2016-08-09-the-tech-behind-live-auction-integration/Prediction%20Bidder%20Screenshot.png" alt="Prediction Bidder UI" /></p>

<p>Keeping our state management and transition code organized with Redux allowed us to achieve a massive amount of reuse of model and controller code between our web interfaces. To solve Redux's <a href="http://stackoverflow.com/q/34570758/807674">async</a> and <a href="http://stackoverflow.com/q/34299460/807674">data conveyance</a> “problems", we built an integration layer for React and Redux called <a href="https://github.com/artsy/react-redux-controller">React Redux Controller</a>.</p>

<p><img src="/images/2016-08-09-the-tech-behind-live-auction-integration/Prediction%20Operator%20Screenshot.png" alt="Prediction Operator UI" /></p>

<p>We found the React+Redux approach to model-view-controller app development to be a major win in what it gave us for maintainability, code reuse, easy testability, and the ability to reason about our code.</p>

<h2>The iOS native app: Eigen</h2>

<p>For users of the Artsy iOS app, known to our engineering team as <a href="https://github.com/artsy/eigen">Eigen</a>, a touch-optimized LAI experience was coded in Swift. It shares the same app with existing Objective-C code as well as <a href="https://facebook.github.io/react-native/">React Native</a> code used for other aspects of the iOS experience. We considered using React Native for this, but we decided to go with more familiar technology to contain the risk.</p>

<p><img src="/images/2016-08-09-the-tech-behind-live-auction-integration/Eigen%20Bidder%20Screenshot.png" alt="Eigen Bidder UI" /></p>

<p>Both of these applications interact with our central Artsy back-end service to pull in artist, artwork, and sale metadata when the user enters the auction. These queries are mediated by a <a href="http://graphql.org/">GraphQL</a> middleware service we call <a href="https://github.com/artsy/metaphysics">Metaphysics</a> (also discussed <a href="/blog/2016/06/19/graphql-for-mobile/">here</a>), which vastly simplified the fetching process in the front-end services. But from that point forward, the apps interact with a brand new auction state management system over a bidirectional <a href="https://en.wikipedia.org/wiki/WebSocket">WebSocket</a> API for live updating.</p>

<h1>The auction state management service: Causality</h1>

<p>The other recently launched piece of software delivered for LAI was a new auction state management system we call Causality. It processes bids and other auction events, computes the derived state of a sale, and hosts the bidirectional WebSocket API.</p>

<p>Causality was developed in Scala, using the <a href="http://doc.akka.io/docs/akka/current/intro/what-is-akka.html">Akka</a> technology suite for distributed computing. At its core is an append-only storage engine, based on <a href="http://doc.akka.io/docs/akka/current/scala/persistence.html">Akka Persistence</a>, with a small library we developed called <a href="https://github.com/artsy/atomic-store">Atomic Store</a> that allowed us to achieve strict consistency, at the cost of maximal throughput -- a trade-off that is explored in the readme of that project.</p>

<p>Lastly, Causality has an <a href="http://doc.akka.io/docs/akka/current/scala/http/introduction.html">Akka HTTP</a>-based API layer, with a WebSocket server implemented using <a href="http://doc.akka.io/docs/akka/current/scala/stream/stream-introduction.html">Akka Streams</a>. Asynchronous updates generated in the event processing logic are published across the cluster using <a href="http://doc.akka.io/docs/akka/current/scala/distributed-pub-sub.html">Akka Distributed Pub/Sub</a>, and they are merged into the WebSocket outflow.</p>

<h1>Pre-bidding, tooling, and other concerns</h1>

<p>In addition to accepting bids placed during a live sale, we also allow users to place bids before the event begins. In practice, this is almost the same workflow as our existing timed auction experience. For this reason, we chose to leverage all of our existing technology. The work of preparing our preexisting tech for LAI involved widespread modifications to our front-end UI, messaging services, admin tooling, and monitoring to make them appropriate for a live sale, as well as a reliable handoff of responsibility from these preexisting front- and back-end services to the new ones at the time the sale goes live.</p>

<p>We relied on our automated test suites, as well as thorough manual testing by the entire Artsy auctions team, to ensure that this handoff functioned smoothly under various circumstances. We will eventually eliminate this duplication. But this will require delicate refactoring of our preexisting tooling, which we will take on, even as we execute a fall auction season significantly busier than the last.</p>

<h1>Reflection</h1>

<p>In the process of architecting our LAI product, we had to make some tough decisions in the face of new challenges. Chief among these were the decisions on where on the spectrum of bleeding-edge technology versus tried-and-true choices to land, for many of our subcomponents. Bleeding-edge tech often offers more elegant and performant solutions, but at the cost of learning curve and risk of immaturity. We also had to carefully prioritize functionality. Choosing wisely througout the process was critical to shipping on time. The rationale behind these decisions and their outcomes will be the result of future pieces.</p>

<p>To close, I want to express huge thanks to the auctions product &amp; engineering team for putting in long hours to design, implement, and troubleshoot the software; the auctions arts team for providing the domain knowledge and operational feedback; and our broader Artsy engineering team, at least half of whom directly contributed code to this effort.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Trying out React]]></title>
    <link href="http://artsy.github.io/blog/2015/04/08/creating-a-dynamic-single-page-app-for-our-genome-team-using-react/"/>
    <updated>2015-04-08T11:30:00+00:00</updated>
    <id>http://artsy.github.io/blog/2015/04/08/creating-a-dynamic-single-page-app-for-our-genome-team-using-react</id>
    <content type="html"><![CDATA[<p>We recently picked up a Rails application that was a few features away from completion. This application allows our <a href="https://www.artsy.net/about/the-art-genome-project">Genome Team</a> to classify multiple artworks based on visual and art historical characteristics. These characteristics, or "genes", can be added, removed, and changed for any of the artworks on the panel.</p>

<center><img src='/images/2015-04-08-creating-a-dynamic-single-page-app-for-our-genome-team-using-react/helix_screenshot.png'></center>


<p>Our genomers are masters of efficiency, and over the years we have worked closely with them to tailor a dynamic interface to their specific workflow.</p>

<p>When we started working on the app, the back-end was organized, modular, and interfaced seamlessly with the Artsy API, but there were still a few front-end features we needed to implement before it could be used by the Genome Team. The app did not use a front-end framework, and as our features scaled it was difficult to keep track of UI state with pure CoffeeScript and global event listeners. Eventually, we decided to stop trying to patch our leaky roof and build a new one.</p>

<!-- more -->


<h3>Choosing a Suitable Framework</h3>

<p>We decided to introduce a front-end framework to make it easier to add new features, and spent a day researching different options. Our requirements were:
- A robust view layer that could work on top of our already-solid Rails back-end,
- A framework performant enough for an interaction-heavy single-page app with hundreds of editable fields autosaving on change,
- A streamlined framework that favors freedom over unnecessary structure.</p>

<p>We chose <a href="http://facebook.github.io/react/">React</a>, Facebook's view layer framework, because it provides much-needed structure and support for components in a single page app without too much boilerplate.</p>

<p>Our plan was to eventually replace all of the existing <code>*.haml.erb</code> templates and global CoffeeScript mixins with discrete React components. We used the <a href="https://github.com/reactjs/react-rails">react-rails</a> gem, which easily integrates React components with Rails views.</p>

<p>In line with the <a href="https://facebook.github.io/react/docs/tutorial.html">React tutorial</a>, we first broke up our UI into functional and visual components. For each component we found the relevant HAML template, converted it into <a href="https://facebook.github.io/react/docs/jsx-in-depth.html">jsx</a> and React components using dummy data, and eventually updated it to accept the correct state from our top-level component which did all of the dynamic fetching and saving. Then we deleted the associated HAML and CoffeeScript code.</p>

<h3>Thinking the React Way</h3>

<p>At this point we have replaced the majority of the app's front-end with React components. We love React because it encourages you to follow certain <a href="http://www.reactivemanifesto.org/">ideological conventions</a>, but it does not force you into a structure that may not exactly align with your goals.</p>

<p>In React, having a single source of truth is ideal. Gone are liberally distributed global event listeners that can conflict and cause pages to get bogged down with transition logic. State is held at the topmost level in React and when state changes, React automatically re-renders only the affected components.</p>

<p>For example, we hold a hash <code>artworks</code> in the highest-level state of the page:
<code>javascript
getInitialState: function() {
  var artworks = _.map(this.props.artwork_ids, function(id) {
    return [id, {
      _id: id,
      isLoaded: false,
      isSelected: false,
      isMinimized: false
    }];
  });
  return {
    artworks: _.object(artworks),
    ...
  }
},
</code></p>

<p>We also store a method at this level to update the <code>artworks</code> state when there is a change:
<code>javascript
updateArtwork: function(artwork_id, cb) {
  // finds an artwork, passes it to callback (cb) to be mutated,
  // sets the mutated artwork on state from the return value of
  // the callback
  var new_artwork = cb(this.state.artworks[artwork_id]);
  var state_copy = this.state;
  state_copy.artworks[artwork_id] = new_artwork;
  this.setState(state_copy);
},
</code></p>

<p>That method is passed to child components, and when there is an update to an <code>artwork</code>, such as when it becomes selected, we invoke it to update all affected components:
<code>javascript
changeIsSelected: function (e) {
  e.preventDefault();
  var newSelectedState = !this.props.artwork.isSelected;
  this.props.updateArtwork(this.props.artwork._id, function(artwork) {
    artwork.isSelected = newSelectedState;
    return artwork;
  })
},
</code></p>

<p>React lets us define our components and interactions in a declarative style instead of stringing together possible transitions triggered by events. Before converting this app to React, we had many bugs around form submission and saving genome progress. However, by modeling state instead of UI transitions, we can easily track changes and save progress incrementally in the background without requiring a page refresh from the user.</p>

<h4>From CoffeeScript to React: Selecting Artworks</h4>

<p>In this app, genomers are able to 'select' artworks on the panel for the purposes of saving and conducting batch actions. In our initial implementation, clicking the 'select all' button would individually click each artwork and used global event listeners to change UI state:</p>

<pre><code class="javascript">($ 'body').on 'click', '.artwork-selector', (evt) -&gt;
  container = $(this)
  currentSlug = container.data('id')
  artworkIdsElement = $('#selected_artwork_ids')
  selectedArtworkIds = _.compact(_.uniq(artworkIdsElement.val().split(',')))
  indexOfCurrentSlug = selectedArtworkIds.indexOf(currentSlug)
  if selectedArtworkIds.indexOf(currentSlug) != -1
    selectedArtworkIds.splice(indexOfCurrentSlug, 1)
    container.text('Not selected')
    container.removeClass('btn-purple')
  else
    selectedArtworkIds.push currentSlug
    container.text('Selected')
    container.addClass('btn-purple')
  $('#selected_artwork_ids').val(selectedArtworkIds.join(','))
  return false
</code></pre>

<p>With React, we store whether or not an artwork is selected as part of our state, and the appearance of elements results from this variable. We use <a href="https://facebook.github.io/react/docs/class-name-manipulation.html">class sets</a> to dynamically alter styles such as button color. When the <code>selected</code> state changes, React re-renders all components that depend on that variable.</p>

<pre><code class="javascript">var SelectedButton = React.createClass({
  changeIsSelected: function (e) {
    e.preventDefault();
    var newSelectedState = !this.props.artwork.isSelected;
    this.props.updateArtwork(this.props.artwork._id, function(artwork) {
      artwork.isSelected = newSelectedState;
      return artwork;
    })
  },
  render: function() {
    var cx = React.addons.classSet;
    var selectedButtonClasses = cx({
      'btn-purple': this.props.artwork.isSelected,
      'btn-tiny': true,
      'btn': true,
      'artwork-selector': true
    });
    return (
      &lt;div className="panel-artwork-actions"&gt;
        &lt;a className={selectedButtonClasses}
           data-id='false'
           href='#'
           onClick={ this.changeIsSelected }&gt;
         {this.props.artwork.isSelected ? '' : 'Not '}Selected&lt;/a&gt;
      &lt;/div&gt;
    )
  }
});
</code></pre>

<h3>Challenges</h3>

<h4>React's Virtual DOM</h4>

<p>React keeps track of a Virtual DOM created by components you define. This can lead to issues, especially when trying to integrate React with jQuery plugins. For example, our modals kept showing up within other components until we explicitly rendered them on the outermost level. We also had issues trying to use an existing drag/drop plugin with the way we set up our state, and ended up <a href="https://gist.github.com/sweir27/4ea941dd717da69527d6">building one from scratch</a>.</p>

<p>React also crashes when the Virtual DOM becomes out-of-sync with the page DOM. We unearthed a mysterious bug in which the browser was automatically inserting a <code>tbody</code> tag when it saw a table rendered without one... causing React (and therefore our entire app) to crash. In order to rectify this, we had to explicitly include these normally optional tags:
<code>javascript
if (geneList.length) {
  var results = (&lt;table className="triple-margin-top"&gt;
                   &lt;thead&gt;{DictionaryView.header}&lt;/thead&gt;
                   &lt;tbody&gt;{geneList}&lt;/tbody&gt;
                 &lt;/table&gt;);
 } else {
   var results = null;
 }
</code></p>

<h4>Working with the React Lifecycle</h4>

<p>Sometimes it is unavoidable to model transitions directly with JavaScript/jQuery, instead of using React's built-in lifecycle methods. In one case, we had to dynamically change the top padding of a component based on the height of a different one. Although we tried to do this using the <a href="https://facebook.github.io/react/docs/component-specs.html">React lifecycle</a> methods, there ended up being too many edge cases and we were having to add more and more states just to avoid:</p>

<pre><code class="javascript">currentTemplateHeight=$('.panel-template-wrap').height();
$('.panel-data-items').css('padding-top', currentTemplateHeight);
</code></pre>

<p>In this case, we found it more straightforward to go with the jQuery solution.</p>

<h3>React == Refactor</h3>

<p>When we started out converting the app to React, it was hard to know whether or not an element should be its own component or if it could exist within another one. Often when we add new features, we have to refactor to make sure that we are reusing components and maintaining a single source of truth.</p>

<p>For example, we originally had one component to hold metadata on an artwork, such as artist, title, and date:
<code>javascript
var PanelArtworkInfo = React.createClass({
  ...
  render: function() {
    var artistName;
    var artworkTitle;
    var artworkDate;
    ...
    if (this.props.artwork.artist &amp;&amp; this.props.artwork.artist['name']) {
      artistName = &lt;ArtistName artwork={this.props.artwork} setTemplateArtistId={this.props.setTemplateArtistId} /&gt;;
    } else {
      artistName = &lt;span&gt;Unattributed&lt;/span&gt;;
    }
    artworkTitle = this.props.artwork.title ? this.props.artwork.title : 'Untitled';
    artworkDate = this.props.artwork.date ? this.props.artwork.date : 'No Date';
    ...
    return (
      &lt;div className="dummy-wrap"&gt;
        &lt;div className="row"&gt;
          ...
          &lt;div className="col-sm-6"&gt;
            &lt;div className="artist-name"&gt;
              {artistName}
            &lt;/div&gt;
            &lt;div className="title"&gt;
              {artworkTitle}
            &lt;/div&gt;
            &lt;div className="date"&gt;
              {artworkDate}
            &lt;/div&gt;
            ...
          &lt;/div&gt;
        &lt;/div&gt;
        ...
      &lt;/div&gt;
    );
  }
});
</code></p>

<p>When we implemented a new 'minimized' view for artworks, we also showed the title and artist, and so we broke these bits of information into separate components:
```javascript
var ArtistName = React.createClass({
  handleClick: function() {
    if (this.props.artwork.artist['name']) {
      this.props.setTemplateArtistId(this.props.artwork.artist['_id'])
    }
  },
  render: function() {
    var artistName;
    if (this.props.artwork.artist &amp;&amp; this.props.artwork.artist['name']) {
      artistName = <a className="artist-as-template-link"
                      data-template-id={this.props.artwork.artist['_id']}
                      onClick={this.handleClick}
                      data-template-type="Artist" href="#">
                    {this.props.artwork.artist['name']}
                  </a>;
    } else if (this.props.artwork['cultural_maker']) {
      artistName = <span>{this.props.artwork['cultural_maker']}</span>;
    } else {
      artistName = <span>Unattributed</span>;
    }
    return (
      <div className="artist-name">
        {artistName}
      </div>
    );
  }
});</p>

<p>var ArtworkTitle = React.createClass({
  render: function() {
    var artworkTitle = this.props.artwork.title ? this.props.artwork.title : 'Untitled';
    return (
      <div className="title">
        {artworkTitle}
      </div>
    );
  }
});</p>

<p>var ArtworkDate = React.createClass({
  render: function() {
    var artworkDate = this.props.artwork.date ? this.props.artwork.date : 'No Date';
    return (
      <div className="date">
        {artworkDate}
      </div>
    );
  }
});
```</p>

<p>And updated our parent to reuse the new child components:
<code>javascript
var PanelArtworkInfo = React.createClass({
  ...
  render: function() {
    ...
    return (
      &lt;div className="dummy-wrap"&gt;
        &lt;div className="row"&gt;
          ...
          &lt;div className="col-sm-6"&gt;
            &lt;ArtistName artwork={this.props.artwork} setTemplateArtistId={this.props.setTemplateArtistId} /&gt;
            &lt;ArtworkTitle artwork={this.props.artwork} /&gt;
            &lt;ArtworkDate artwork={this.props.artwork} /&gt;
            ...
          &lt;/div&gt;
        &lt;/div&gt;
        ...
      &lt;/div&gt;
    );
  }
});
</code></p>

<h3>Writing Specs</h3>

<p>All of the existing specs for the app were written in RSpec, so we chose to write integration tests using RSpec+Capybara. The headless Capybara webkit did not integrate with our React setup, so we switched to using Selenium as our Capybara JavaScript driver (which also conveniently let us debug our specs within the browser).</p>

<p>Our main challenge with specs had to do with RSpec not waiting long enough for components (such as autocomplete results) to appear, perhaps due to React's Virtual DOM. We spent many sad hours debugging spurious tests, and even included a few dreaded 'sleep' commands. Eventually, we integrated the <a href="https://github.com/y310/rspec-retry">rspec-retry</a> gem to retry spurious tests during CI.</p>

<h3>Conclusion</h3>

<p>Converting our app to use a React-based front-end went surprisingly smoothly. We were able to incrementally change certain templates to React components, which made it easy to test as we went along. Additionally, our development time in adding new features since then has decreased dramatically. It is much easier to add new components or edit existing ones when there is a single source of truth and you don't have to search through global event listeners.</p>

<p>Choosing a front-end framework is non-trivial but incredibly important, and we are glad we found React. Because it does not require much overhead and it is possible to only use it on a portion of a page, React can be integrated into small or large projects. Although we deliberated for a long time over whether or not to use a framework, we never regretted moving to React and investing in the future of the app.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[We open sourced our Isomorphic Javascript website]]></title>
    <link href="http://artsy.github.io/blog/2014/09/05/we-open-sourced-our-isomorphic-javascript-website/"/>
    <updated>2014-09-05T15:09:00+00:00</updated>
    <id>http://artsy.github.io/blog/2014/09/05/we-open-sourced-our-isomorphic-javascript-website</id>
    <content type="html"><![CDATA[<p><img src="/images/2014-09-05-we-open-sourced-our-isomorphic-javascript-website/force.png" alt="May The Force be With You" /></p>

<p>Today we're happy to announce we've open sourced the entire Artsy.net web app, <a href="https://github.com/artsy/force">Force</a>.</p>

<p>Over the past few months, we've rewritten our web front-end to move off Rails and on to a <a href="http://nodejs.org/">Node.js</a> stack that shares Javascript code and rendering between the server and client, otherwise known as <a href="http://nerds.airbnb.com/isomorphic-JavaScript-future-web-apps/">Isomorphic Javascript</a>. After migrating to this new stack, we open-sourced our boilerplate, <a href="http://ezeljs.com">Ezel</a>, and have now gone a step further and open sourced Artsy.net.</p>

<!-- more -->


<h2>Isomorphic vs Monolithic</h2>

<p>Our transition to an isomorphic Javascript stack has been very successful albeit with some speed bumps. If you're interested in the details we've written <a href="http://artsy.github.io/blog/2013/11/30/rendering-on-the-server-and-client-in-node-dot-js/">a blog post</a>, given a talk at <a href="https://www.joyent.com/developers/videos/node-js-on-the-road-nyc-craig-spaeth-brennan-moore">Node on the Road</a> (slides <a href="http://www.slideshare.net/craigspaeth/artsy-node-on-the-roady-slides">here</a>), and another more extensive talk at <a href="http://www.hakkalabs.co/articles/monolithic-to-distributed-how-artsy-transitioned-from-ruby-on-rails-to-node-js-and-isomorphic-javascript#">this meetup</a>.</p>

<p>The short story is that we moved from a monolithic rails app to a couple of Node servers on Heroku. This vastly improved the performance of our site and our own development speed. Using the patterns in Ezel, we are able to tailor assets packages to specific pages and render some of the page on the server. This cut our page-load in half (from 6.5 seconds to under 3 seconds) and our tests take about 5 minutes (down from around 5 hours!) with little reduction in coverage. Performance numbers aside, our real win was dramatically improved development speed due to some architecture decisions we made.</p>

<h2>Modularity</h2>

<p><a href="https://artsy.net/artwork/nathan-sawaya-red-head"><img src="/images/2014-09-05-we-open-sourced-our-isomorphic-javascript-website/sawaya.jpg" alt="Nathan Sawaya, Red Head, 2009" /></a></p>

<p>One of the biggest takeaways from the transition is the pleasure of modularity. By breaking our project up into smaller reusable pieces such as <a href="https://github.com/artsy/ezel#project-vs-apps-vs-components">apps &amp; components</a> we make it easier to experiment, test, and refactor with confidence knowing our code is encapsulated into clearly defined pieces.</p>

<p>For instance, we recently redesigned our <a href="https://artsy.net/about">about</a> page. To gradually introduce the new page, we simply started a new about2 app along side our old about app which you can see <a href="https://github.com/artsy/force/tree/0d5a49da08e94a91b3f23c7cd1005c1e83da7ba5/apps">a little back in Force's history</a>. This let us push code into the new about2 app with confidence it wasn't touching other parts of the stack. When it was time to ship it, we simply deleted the old about app folder and search and replaced "about2" to "about". There was no need to dig around various stylesheets, views, etc. folders looking for places where code for the old about page might still live.</p>

<p><a href="https://github.com/artsy/ezel#components">Components</a> are particularly useful for re-usability. For instance building <a href="https://artsy.net/gene/abstract-expressionism">this gene page</a> (source code <a href="https://github.com/artsy/force/tree/master/apps/gene">here</a>) was mostly a matter of pulling in various components like a <a href="https://github.com/artsy/force/tree/master/components/follow_button">follow button</a>, a <a href="https://github.com/artsy/force/tree/master/components/filter">filter</a> component, this <a href="https://github.com/artsy/force/tree/master/components/artist_fillwidth_list">artist fill-width layout</a>, etc. Because the CSS for those components are clearly self-contained it's easy to build up a small asset package that uses only the minimal CSS needed which you can see <a href="https://github.com/artsy/force/blob/master/assets/gene.styl">here</a>.</p>

<p>We're so convinced this encapsulation is important that we've updated Ezel to <a href="https://github.com/artsy/ezel/tree/master/src/js-example/apps/commits/public/images">use app/component-level public folders</a> by default so you can even modularize static assets, like images, and keep them coupled with their respective apps/components.</p>

<h2>Open Source by Default</h2>

<p><img src="/images/2014-09-05-we-open-sourced-our-isomorphic-javascript-website/octocat.jpg" alt="Ocotcat" /></p>

<p>Even though Force isn't a library, we have open-soured many of its components and libraries. Before open sourcing Force, we open sourced app-specific modules such as <a href="https://github.com/artsy/artsy-backbone-mixins">these backbone mixins</a> <a href="https://github.com/artsy/artsy-passport">this Artsy API authentication library</a>, or <a href="https://github.com/artsy/backbone-cache-sync">this module</a> we use to cache server-side Backbone requests.</p>

<p>Open-sourcing Force was pretty straightforward but we needed to make our sensitive keys/secrets private while not complicating development. To do this we wrote a .env file and uploaded it as a private gist that gets downloaded when setting up the app. We wanted to spread this open-source-by-default culture so we decided to update Ezel's configuration to be able to use a .env file in this way as well. This makes it easy keep your sensitive configuration data private while allowing the rest of your app code to be open source. You can read more about this in Ezel's <a href="https://github.com/artsy/ezel#build-scripts--configuration">Build Scripts &amp; Configuration docs</a>.</p>

<h2>Spreading The Love</h2>

<p>Force serves as an example of how we structured a large <a href="http://ezeljs.com">Ezel</a> project and contains the full commit history of its construction. Unfortunately, due to image licensing issues, we cannot open up the Artsy API and therefore this repository can't serve as a runnable clone of our website. However, we will continue to merge our production code into it. If you have any questions feel free to hit us up on twitter: <a href="https://twitter.com/craigspaeth">@craigspaeth</a>, <a href="https://twitter.com/dzucconi">@dzucconi</a>, <a href="https://twitter.com/zamiang">@zamiang</a>.</p>

<p>We're excited to continue pushing open source at Artsy. For more exciting open source projects take a look at <a href="https://github.com/artsy">our GitHub profile</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rendering on the Server and Client in Node.js]]></title>
    <link href="http://artsy.github.io/blog/2013/11/30/rendering-on-the-server-and-client-in-node-dot-js/"/>
    <updated>2013-11-30T22:38:00+00:00</updated>
    <id>http://artsy.github.io/blog/2013/11/30/rendering-on-the-server-and-client-in-node-dot-js</id>
    <content type="html"><![CDATA[<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/isomorphic.png" alt="Diagram of Shared Server/Client Architecture" /></p>

<p>At Artsy we've been building <a href="http://nodejs.org/">Node.js</a> applications that share code and rendering between the server and browser. We've seen many benefits from this -- pages load faster, we can optimize SEO, developers are more productive, and JavaScript coding is just an overall better experience.</p>

<p>Today we're happy to announce <a href="http://ezeljs.com/">Ezel</a>, our open source boilerplate we use to bootstrap our Node projects and the <a href="https://github.com/artsy/benv">various</a> <a href="https://github.com/artsy/backbone-super-sync">node</a> <a href="https://github.com/artsy/sharify">modules</a> that built up to it.</p>

<p>In his article, <a href="http://nerds.airbnb.com/isomorphic-JavaScript-future-web-apps/"><em>Isomorphic JavaScript: The Future of Web Apps</em></a>, Spike Brehm from AirBnB describes this growing trend well and we're excited to be a part of it. In this article I'll tell Artsy's story of moving from a single monolithic application to modular <a href="http://backbonejs.org/">Backbone</a> apps that run in Node and the browser and consume our external API.</p>

<!-- more -->


<h2>Growing Pains</h2>

<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/rails-evolution.png" alt="Evolution of Artsy SOA Diagramm" /></p>

<p>Artsy started as a mostly standard <a href="http://rubyonrails.org/">Rails</a> app almost three years ago. In these beginnings we were wildly productive and owe a lot of props to this great framework. However as time went on we started to deviate from the conventional Rails path until we were hardly leveraging much Rails at all. To support an early iOS app we used <a href="https://github.com/intridea/grape">Grape</a> to build an API. While building our API we wrote a lot of client-side JavaScript and soon integrated <a href="http://backbonejs.org/">Backbone</a> for organization. Eventually we cleanly separated our project into a single page Backbone app talking to our API all on inside of this original repository.</p>

<p>We knew we were outgrowing this monolithic project because we had some clear problems...</p>

<ul>
<li>Slow initial page loads because of lacking server-side rendering. Twitter <a href="https://blog.twitter.com/2012/improving-performance-twittercom">describes this problem well</a>.</li>
<li>Slow following client-side renders because of downloading large asset packages without clear ways to break them up.</li>
<li>SEO issues like building <a href="https://developers.google.com/webmasters/ajax-crawling/docs/specification">escaped fragment</a> pages in Ruby on the server while our users saw what JavaScript rendered on the client.</li>
<li>Maintaining duplicated Ruby/JavaScript code such as templates, date libraries, etc.</li>
<li>Very slow and brittle tests. We had a massive integration test suite consisting of over 3000 <a href="https://github.com/jnicklas/capybara">Capybara</a> tests that took hours to run because we lacked good JavaScript testing tools.</li>
<li>Poor mobile experience from trying to responsively scale down a large single page app with bloated and unused assets.</li>
<li>Slow asset compilation, server boot, and general build times. Productivity suffered greatly as more code was added to the same monolithic project.</li>
</ul>


<h2>There's Got to Be a Better Way</h2>

<p>A monolithic app that treats it's client-side code as a second class citizen was clearly not going to scale. Our poor mobile web experience was a good candidate to try something new. So we started building a separate mobile optimized website (m.artsy.net).</p>

<p>Some goals became clear:</p>

<ul>
<li>Better client-side tools from JavaScript testing to package managers.</li>
<li>Share rendering code server/client to reduce duplication and optimize initial page load.</li>
<li>Flexibility. We needed a way to divide our app into smaller chunks with smaller asset packages.</li>
</ul>


<h2>Choosing Technology</h2>

<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/tech.png" alt="Logos of Browserify, Express, and Backbone" /></p>

<p>Node was a clear choice because it made sharing rendering code server/client possible where other languages and frameworks struggle to do so. There were some existing Node projects that accomplish this such as <a href="http://derbyjs.com/">Derby</a> and <a href="https://github.com/airbnb/rendr">Rendr</a>. However, adopting these had challenges of their own including being difficult to integrate with our API, learning unnecessary conventions, or being early prototypes with lacking documentation.</p>

<p>We wanted an approach that breaks our app into smaller, more flexible, pieces. Not all of Artsy needs to be a thick-client app, or even use much client-side JavaScript at all. Adopting an existing solution and combining most of the server and client into a shared abstraction seemed like an unnecessary black box. After trying many other frameworks we found a combination of lower-level tools to be a clear winner.</p>

<p>We open sourced this combination of tools and patterns into <a href="http://ezeljs.com/">Ezel</a>. Ezel is a light-weight boilerplate project using <a href="http://expressjs.com/">Express</a> and <a href="http://backbonejs.org/">Backbone</a> for structure, and <a href="http://browserify.org/">Browserify</a> to compose modules that can be shared server/client.</p>

<h2>Sharing and Rendering Server/Client</h2>

<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/rendering.png" alt="Diagram of Server + Client Render" /></p>

<p>To share rendering code server/client we had to make sure our templates and objects being passed in to them could work the same server/client.</p>

<h3>Sharing Objects (Backbone Models)</h3>

<p><a href="http://browserify.org/">Browserify</a> lets you write modules that can run in Node or the browser. Since Backbone is able to be required on the server out of the box, it's easy to write models and collections that can be required on both sides with Browserify. However, there are two main speed bumps in doing this:</p>

<ol>
<li><p>Backbone uses AJAX for persistence.</p>

<p>We needed a Backbone.sync adapter that makes HTTP requests server-side, so we wrote one and <a href="https://github.com/artsy/backbone-super-sync">it's open sourced.</a></p></li>
<li><p>Data from the server needed to be shared in modules that are used server/client.</p>

<p>For instance, our API is an external URL stored in an environment variable. We needed to use this variable in a module that will be required on the server and the client with Browserify. <a href="http://backbonejs.org/#FAQ-bootstrap">Bootstrapping data</a> is a common technique to share data from the server by embedding JavaScript in the initial HTML and exposing that data globally to the client. To avoid exposing globals we open sourced a tiny module called <a href="https://github.com/artsy/sharify">sharify</a>.</p></li>
</ol>


<h3>Sharing Templates</h3>

<p>Browserify even lets you share non-JavaScript components server/client using <a href="https://github.com/substack/node-browserify#list-of-source-transforms">transforms</a>. To reuse our <a href="http://jade-lang.com/">jade</a> templates server/client it was a simple matter of using the <a href="https://github.com/OliverJAsh/node-jadeify2">jadeify</a> transform.</p>

<h3>All Together Now</h3>

<p>With templates and models require-able server/client, sharing rendering code became much simpler. Below is an example using the same artwork model and detail template server/client.</p>

<p>Shared Backbone "Artwork" model to be required server/client:</p>

<pre><code class="javascript models/artwork.js">var Backbone = require('backbone'),
    API_URL = require('sharify').data.API_URL;

module.exports = Artwork = Backbone.Model.extend({

  url: API_URL + '/api/v1/artwork'

});
</code></pre>

<p>Shared partial jade template used server/client:</p>

<pre><code class="jade templates/artwork-details.jade">h1= artwork.get('artist').name
h2= artwork.get('title')
</code></pre>

<p>Full server-side page template including the partial:</p>

<pre><code class="jade templates/artwork-page.jade">doctype 5
html
  head
    title Artsy | #{artwork.get('title')}
  body
    include artwork-details
    != sharify.script()
</code></pre>

<p>Route handler that uses the model server-side:</p>

<pre><code class="javascript app.js">//...
var Artwork = require('models/artwork.js');

app.get('/artwork/:id', function(req, res) {
  new Artwork({ id: req.params.id }).fetch({
    success: function(artwork) {
      // Boostrap artwork data into sharify
      res.locals.sharify.data.ARTWORK_JSON = artwork.toJSON();
      res.render('artwork-page', { artwork: artwork });
    }
  });
});
</code></pre>

<p>Client side code that requires the partial template and model:</p>

<pre><code class="javascript client.js">var Artwork = require('models/artwork.js'),
    ARTWORK_JSON = require('sharify').data.ARTWORK_JSON,
    detailsTemplate = require('templates/artwork-details.jade');

var artwork = new Artwork(ARTWORK_JSON);
artwork.on('change', function() {
  $('body').html(detailsTemplate({ artwork: artwork }));
});
</code></pre>

<h2>Developer Happiness</h2>

<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/so-much-win.png" alt="Happy Developer Image" /></p>

<p>Not only does sharing code server/client let you easily optimize page rendering for fast page loads, but development becomes a lot nicer because we can reuse server-side JavaScript tools including...</p>

<h3>Package Managers</h3>

<p>With Browserify we were able to use npm as a package manager for server or client-side dependencies. There are <a href="http://bower.io/">other</a> <a href="http://component.io/">package</a> <a href="http://jamjs.org/">managers</a> for the client-side. However, because we were already using npm (and npm supports git urls), we could usually point to the project hosted on npm or Github without having to fork it.</p>

<p>For projects that don't support CommonJS modules (or npm), often one can still use npm and requires like so:</p>

<pre><code class="json">"devDependencies": {
  "zepto": "git://github.com/madrobby/zepto.git#c074a94f0f26dc946f1c501f5f45d603adada44d"
}
</code></pre>

<pre><code class="javascript client.js">// Require the base Zepto library (attaches `Zepto` to window)
require('zepto/src/zepto.js');
// Attach Zepto's plugins
require('zepto/src/event.js');
require('zepto/src/detect.js');
// ....
</code></pre>

<h3>Testing</h3>

<p>Testing is light-years ahead because you can test all of your code in Node headless. I wrote <a href="/blog/2013/06/14/writing-headless-backbone-tests-with-node-dot-js/">an article</a> on this a while back, and now with Browserify it's even better.</p>

<p>Models, templates, and other modules that are shared server/client can be required into <a href="http://visionmedia.github.io/mocha/">mocha</a> and tested server-side without extra effort. For more view-like client-side code that depends on DOM APIs, pre-rendered HTML, etc., we open sourced a library called <a href="https://github.com/craigspaeth/benv">benv</a> to help build a fake browser environment in Node for testing.</p>

<h3>Modularity</h3>

<p>We wanted to avoid a monolithic organization that groups code by type such as "stylesheets", "javascripts", "controllers", etc.. Not only is this a maintenance problem as it makes boundaries of your app unclear, but it also affects your users because it encourages grouping assets into large monolithic packages that take a long time to download.</p>

<p>Instead, we borrowed a page from <a href="http://stackoverflow.com/questions/2472984/django-and-project-application-organization">Django</a> and broke up our project into smaller conceptual pieces called "apps" (small express sub-applications mounted into the main project) and "components" (portions of reusable UI such as a modal widget). This let us easily maintain decoupled segments of our project and build up smaller asset packages through Browserify's <code>require</code>s and <a href="http://learnboost.github.io/stylus/docs/import.html">Stylus</a>' <code>import</code>s. For more details on how this is done please check out <a href="http://ezeljs.com/">Ezel</a>, its <a href="https://github.com/artsy/ezel#project-vs-apps-vs-components">organization</a>, and <a href="https://github.com/artsy/ezel#asset-pipeline">asset pipeline</a> docs.</p>

<p>It's also worth noting, to avoid CSS spaghetti we followed a simple convention of name-spacing all of our classes/ids by the app or component name it was a part of. This was inspired by a <a href="http://philipwalton.com/articles/css-architecture/">blog post from Philip Walton</a>.</p>

<h2>Success!</h2>

<p>With this new architecture and set of Node tools we've seen enormous benefits compared to the pains of developing Backbone in a monolithic project with lacking JavaScript tools. Our mobile web experience is much better, we can render more content on the server for SEO and faster page loads, our test/build/deploy cycles went from hours to minutes, our developer on-boarding time went from days to minutes, and overall developer happiness has significantly improved.</p>

<p>It's an exciting time to be developing JavaScript apps and we will continue to open source our efforts wherever possible. Thanks and <a href="https://github.com/artsy">follow us on Github</a>!</p>
]]></content>
  </entry>
  
</feed>
