<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: javascript | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/javascript/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2016-08-15T15:14:40+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Tech Behind Live Auction Integration]]></title>
    <link href="http://artsy.github.io/blog/2016/08/09/the-tech-behind-live-auction-integration/"/>
    <updated>2016-08-09T11:30:00+00:00</updated>
    <id>http://artsy.github.io/blog/2016/08/09/the-tech-behind-live-auction-integration</id>
    <content type="html"><![CDATA[<p>In late June, the <a href="https://www.artsy.net/auctions/">Artsy auctions</a> team launched our Live Auction Integration (LAI) product. It allows people to participate online in live sales held at auction houses <a href="https://www.artsy.net/auction-partnerships">that partner with Artsy</a>. It was a big project, begun in December, involving both brand new software and extensive integration work with the rest of our systems. This is the first in what will be a series of blog posts discussing the engineering work we did to get a complex product from inception to launch in such a brief time window, with a go-live deadline set in stone weeks in advance. In this, I’ll dig into what we shipped on a high level, as well as some of the overarching technical decisions.</p>

<!-- more -->


<p>LAI raised challenges that were novel to our engineering team. The product is a real-time experience from the perspectives of the bidder and the auction house. Producing that experience requires a complex human + computer system. There are two main flows of information: from auction house to bidder, and vice versa. These are mediated by our systems and staff as follows:</p>

<ul>
<li>As bids occur in the auction house sale room, an Artsy operator working on-site inputs that activity into a web interface so that online participants can keep track of what’s happening.</li>
<li>As online participants place bids, our system records those as “prospective bids”, and an Artsy bidding clerk on site at the auction house bids on their behalf in the auction house. As those bids are recognized, they are reflected back to all participants, through the prior flow.</li>
</ul>


<p>To make this easier to visualize:</p>

<p><img src="/images/2016-08-09-the-tech-behind-live-auction-integration/Artsy%20Live%20Auction%20Integration%20flow.png" alt="Artsy Live Auction Integration Flow" /></p>

<p>This needs to happen in a tight loop to allow online bidders to be competitive with those in the room and via auction house phone clerks. The architecture and UX of the LAI product were optimized for that goal. In addition, we built the system to integrate with live events hosted by our partners. As the events are outside our direct control, there are many, many ways things can deviate from this idealized flow. We had to carefully account for these situations.</p>

<p>Where possible, we leveraged our existing auctions technology. But we took the opportunity to upgrade that technology in some places and chose new approaches in others. Meanwhile, we were running the busiest Artsy auction season to date, and we had to ensure that we weren’t disrupting our existing stack. Below, I discuss the pieces of the end-to-end product.</p>

<h1>The Live user experience</h1>

<p>When the live auction actually begins, participants and Artsy staff interact with the system with front-end software developed from scratch. Web users (desktop and mobile) and staff use a new, dedicated Artsy Live web application, which is implemented in a project we call Prediction. iOS Artsy App users can also participate with newly developed UX within that app.</p>

<h2>The web app: Prediction</h2>

<p>Our bidder and operator web interfaces are implemented in an application we call Prediction, a <a href="https://medium.com/@mjackson/universal-javascript-4761051b7ae9#.ev1yd3juy">universal</a> <a href="https://facebook.github.io/react/">React</a>+<a href="http://redux.js.org/">Redux</a> Javascript app, served from an <a href="http://expressjs.com/">Express</a> server. Using React allowed us to completely share our view layer code for prerendering in the server and making updates in the client.</p>

<p><img src="/images/2016-08-09-the-tech-behind-live-auction-integration/Prediction%20Bidder%20Screenshot.png" alt="Prediction Bidder UI" /></p>

<p>Keeping our state management and transition code organized with Redux allowed us to achieve a massive amount of reuse of model and controller code between our web interfaces. To solve Redux's <a href="http://stackoverflow.com/q/34570758/807674">async</a> and <a href="http://stackoverflow.com/q/34299460/807674">data conveyance</a> “problems", we built an integration layer for React and Redux called <a href="https://github.com/artsy/react-redux-controller">React Redux Controller</a>.</p>

<p><img src="/images/2016-08-09-the-tech-behind-live-auction-integration/Prediction%20Operator%20Screenshot.png" alt="Prediction Operator UI" /></p>

<p>We found the React+Redux approach to model-view-controller app development to be a major win in what it gave us for maintainability, code reuse, easy testability, and the ability to reason about our code.</p>

<h2>The iOS native app: Eigen</h2>

<p>For users of the Artsy iOS app, known to our engineering team as <a href="https://github.com/artsy/eigen">Eigen</a>, a touch-optimized LAI experience was coded in Swift. It shares the same app with existing Objective-C code as well as <a href="https://facebook.github.io/react-native/">React Native</a> code used for other aspects of the iOS experience. We considered using React Native for this, but we decided to go with more familiar technology to contain the risk.</p>

<p><img src="/images/2016-08-09-the-tech-behind-live-auction-integration/Eigen%20Bidder%20Screenshot.png" alt="Eigen Bidder UI" /></p>

<p>Both of these applications interact with our central Artsy back-end service to pull in artist, artwork, and sale metadata when the user enters the auction. These queries are mediated by a <a href="http://graphql.org/">GraphQL</a> middleware service we call <a href="https://github.com/artsy/metaphysics">Metaphysics</a> (also discussed <a href="/blog/2016/06/19/graphql-for-mobile/">here</a>), which vastly simplified the fetching process in the front-end services. But from that point forward, the apps interact with a brand new auction state management system over a bidirectional <a href="https://en.wikipedia.org/wiki/WebSocket">WebSocket</a> API for live updating.</p>

<h1>The auction state management service: Causality</h1>

<p>The other recently launched piece of software delivered for LAI was a new auction state management system we call Causality. It processes bids and other auction events, computes the derived state of a sale, and hosts the bidirectional WebSocket API.</p>

<p>Causality was developed in Scala, using the <a href="http://doc.akka.io/docs/akka/current/intro/what-is-akka.html">Akka</a> technology suite for distributed computing. At its core is an append-only storage engine, based on <a href="http://doc.akka.io/docs/akka/current/scala/persistence.html">Akka Persistence</a>, with a small library we developed called <a href="https://github.com/artsy/atomic-store">Atomic Store</a> that allowed us to achieve strict consistency, at the cost of maximal throughput -- a trade-off that is explored in the readme of that project.</p>

<p>Lastly, Causality has an <a href="http://doc.akka.io/docs/akka/current/scala/http/introduction.html">Akka HTTP</a>-based API layer, with a WebSocket server implemented using <a href="http://doc.akka.io/docs/akka/current/scala/stream/stream-introduction.html">Akka Streams</a>. Asynchronous updates generated in the event processing logic are published across the cluster using <a href="http://doc.akka.io/docs/akka/current/scala/distributed-pub-sub.html">Akka Distributed Pub/Sub</a>, and they are merged into the WebSocket outflow.</p>

<h1>Pre-bidding, tooling, and other concerns</h1>

<p>In addition to accepting bids placed during a live sale, we also allow users to place bids before the event begins. In practice, this is almost the same workflow as our existing timed auction experience. For this reason, we chose to leverage all of our existing technology. The work of preparing our preexisting tech for LAI involved widespread modifications to our front-end UI, messaging services, admin tooling, and monitoring to make them appropriate for a live sale, as well as a reliable handoff of responsibility from these preexisting front- and back-end services to the new ones at the time the sale goes live.</p>

<p>We relied on our automated test suites, as well as thorough manual testing by the entire Artsy auctions team, to ensure that this handoff functioned smoothly under various circumstances. We will eventually eliminate this duplication. But this will require delicate refactoring of our preexisting tooling, which we will take on, even as we execute a fall auction season significantly busier than the last.</p>

<h1>Reflection</h1>

<p>In the process of architecting our LAI product, we had to make some tough decisions in the face of new challenges. Chief among these were the decisions on where on the spectrum of bleeding-edge technology versus tried-and-true choices to land, for many of our subcomponents. Bleeding-edge tech often offers more elegant and performant solutions, but at the cost of learning curve and risk of immaturity. We also had to carefully prioritize functionality. Choosing wisely througout the process was critical to shipping on time. The rationale behind these decisions and their outcomes will be the result of future pieces.</p>

<p>To close, I want to express huge thanks to the auctions product &amp; engineering team for putting in long hours to design, implement, and troubleshoot the software; the auctions arts team for providing the domain knowledge and operational feedback; and our broader Artsy engineering team, at least half of whom directly contributed code to this effort.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Trying out React]]></title>
    <link href="http://artsy.github.io/blog/2015/04/08/creating-a-dynamic-single-page-app-for-our-genome-team-using-react/"/>
    <updated>2015-04-08T11:30:00+00:00</updated>
    <id>http://artsy.github.io/blog/2015/04/08/creating-a-dynamic-single-page-app-for-our-genome-team-using-react</id>
    <content type="html"><![CDATA[<p>We recently picked up a Rails application that was a few features away from completion. This application allows our <a href="https://www.artsy.net/about/the-art-genome-project">Genome Team</a> to classify multiple artworks based on visual and art historical characteristics. These characteristics, or "genes", can be added, removed, and changed for any of the artworks on the panel.</p>

<center><img src='/images/2015-04-08-creating-a-dynamic-single-page-app-for-our-genome-team-using-react/helix_screenshot.png'></center>


<p>Our genomers are masters of efficiency, and over the years we have worked closely with them to tailor a dynamic interface to their specific workflow.</p>

<p>When we started working on the app, the back-end was organized, modular, and interfaced seamlessly with the Artsy API, but there were still a few front-end features we needed to implement before it could be used by the Genome Team. The app did not use a front-end framework, and as our features scaled it was difficult to keep track of UI state with pure CoffeeScript and global event listeners. Eventually, we decided to stop trying to patch our leaky roof and build a new one.</p>

<!-- more -->


<h3>Choosing a Suitable Framework</h3>

<p>We decided to introduce a front-end framework to make it easier to add new features, and spent a day researching different options. Our requirements were:
- A robust view layer that could work on top of our already-solid Rails back-end,
- A framework performant enough for an interaction-heavy single-page app with hundreds of editable fields autosaving on change,
- A streamlined framework that favors freedom over unnecessary structure.</p>

<p>We chose <a href="http://facebook.github.io/react/">React</a>, Facebook's view layer framework, because it provides much-needed structure and support for components in a single page app without too much boilerplate.</p>

<p>Our plan was to eventually replace all of the existing <code>*.haml.erb</code> templates and global CoffeeScript mixins with discrete React components. We used the <a href="https://github.com/reactjs/react-rails">react-rails</a> gem, which easily integrates React components with Rails views.</p>

<p>In line with the <a href="https://facebook.github.io/react/docs/tutorial.html">React tutorial</a>, we first broke up our UI into functional and visual components. For each component we found the relevant HAML template, converted it into <a href="https://facebook.github.io/react/docs/jsx-in-depth.html">jsx</a> and React components using dummy data, and eventually updated it to accept the correct state from our top-level component which did all of the dynamic fetching and saving. Then we deleted the associated HAML and CoffeeScript code.</p>

<h3>Thinking the React Way</h3>

<p>At this point we have replaced the majority of the app's front-end with React components. We love React because it encourages you to follow certain <a href="http://www.reactivemanifesto.org/">ideological conventions</a>, but it does not force you into a structure that may not exactly align with your goals.</p>

<p>In React, having a single source of truth is ideal. Gone are liberally distributed global event listeners that can conflict and cause pages to get bogged down with transition logic. State is held at the topmost level in React and when state changes, React automatically re-renders only the affected components.</p>

<p>For example, we hold a hash <code>artworks</code> in the highest-level state of the page:
<code>javascript
getInitialState: function() {
  var artworks = _.map(this.props.artwork_ids, function(id) {
    return [id, {
      _id: id,
      isLoaded: false,
      isSelected: false,
      isMinimized: false
    }];
  });
  return {
    artworks: _.object(artworks),
    ...
  }
},
</code></p>

<p>We also store a method at this level to update the <code>artworks</code> state when there is a change:
<code>javascript
updateArtwork: function(artwork_id, cb) {
  // finds an artwork, passes it to callback (cb) to be mutated,
  // sets the mutated artwork on state from the return value of
  // the callback
  var new_artwork = cb(this.state.artworks[artwork_id]);
  var state_copy = this.state;
  state_copy.artworks[artwork_id] = new_artwork;
  this.setState(state_copy);
},
</code></p>

<p>That method is passed to child components, and when there is an update to an <code>artwork</code>, such as when it becomes selected, we invoke it to update all affected components:
<code>javascript
changeIsSelected: function (e) {
  e.preventDefault();
  var newSelectedState = !this.props.artwork.isSelected;
  this.props.updateArtwork(this.props.artwork._id, function(artwork) {
    artwork.isSelected = newSelectedState;
    return artwork;
  })
},
</code></p>

<p>React lets us define our components and interactions in a declarative style instead of stringing together possible transitions triggered by events. Before converting this app to React, we had many bugs around form submission and saving genome progress. However, by modeling state instead of UI transitions, we can easily track changes and save progress incrementally in the background without requiring a page refresh from the user.</p>

<h4>From CoffeeScript to React: Selecting Artworks</h4>

<p>In this app, genomers are able to 'select' artworks on the panel for the purposes of saving and conducting batch actions. In our initial implementation, clicking the 'select all' button would individually click each artwork and used global event listeners to change UI state:</p>

<pre><code class="javascript">($ 'body').on 'click', '.artwork-selector', (evt) -&gt;
  container = $(this)
  currentSlug = container.data('id')
  artworkIdsElement = $('#selected_artwork_ids')
  selectedArtworkIds = _.compact(_.uniq(artworkIdsElement.val().split(',')))
  indexOfCurrentSlug = selectedArtworkIds.indexOf(currentSlug)
  if selectedArtworkIds.indexOf(currentSlug) != -1
    selectedArtworkIds.splice(indexOfCurrentSlug, 1)
    container.text('Not selected')
    container.removeClass('btn-purple')
  else
    selectedArtworkIds.push currentSlug
    container.text('Selected')
    container.addClass('btn-purple')
  $('#selected_artwork_ids').val(selectedArtworkIds.join(','))
  return false
</code></pre>

<p>With React, we store whether or not an artwork is selected as part of our state, and the appearance of elements results from this variable. We use <a href="https://facebook.github.io/react/docs/class-name-manipulation.html">class sets</a> to dynamically alter styles such as button color. When the <code>selected</code> state changes, React re-renders all components that depend on that variable.</p>

<pre><code class="javascript">var SelectedButton = React.createClass({
  changeIsSelected: function (e) {
    e.preventDefault();
    var newSelectedState = !this.props.artwork.isSelected;
    this.props.updateArtwork(this.props.artwork._id, function(artwork) {
      artwork.isSelected = newSelectedState;
      return artwork;
    })
  },
  render: function() {
    var cx = React.addons.classSet;
    var selectedButtonClasses = cx({
      'btn-purple': this.props.artwork.isSelected,
      'btn-tiny': true,
      'btn': true,
      'artwork-selector': true
    });
    return (
      &lt;div className="panel-artwork-actions"&gt;
        &lt;a className={selectedButtonClasses}
           data-id='false'
           href='#'
           onClick={ this.changeIsSelected }&gt;
         {this.props.artwork.isSelected ? '' : 'Not '}Selected&lt;/a&gt;
      &lt;/div&gt;
    )
  }
});
</code></pre>

<h3>Challenges</h3>

<h4>React's Virtual DOM</h4>

<p>React keeps track of a Virtual DOM created by components you define. This can lead to issues, especially when trying to integrate React with jQuery plugins. For example, our modals kept showing up within other components until we explicitly rendered them on the outermost level. We also had issues trying to use an existing drag/drop plugin with the way we set up our state, and ended up <a href="https://gist.github.com/sweir27/4ea941dd717da69527d6">building one from scratch</a>.</p>

<p>React also crashes when the Virtual DOM becomes out-of-sync with the page DOM. We unearthed a mysterious bug in which the browser was automatically inserting a <code>tbody</code> tag when it saw a table rendered without one... causing React (and therefore our entire app) to crash. In order to rectify this, we had to explicitly include these normally optional tags:
<code>javascript
if (geneList.length) {
  var results = (&lt;table className="triple-margin-top"&gt;
                   &lt;thead&gt;{DictionaryView.header}&lt;/thead&gt;
                   &lt;tbody&gt;{geneList}&lt;/tbody&gt;
                 &lt;/table&gt;);
 } else {
   var results = null;
 }
</code></p>

<h4>Working with the React Lifecycle</h4>

<p>Sometimes it is unavoidable to model transitions directly with JavaScript/jQuery, instead of using React's built-in lifecycle methods. In one case, we had to dynamically change the top padding of a component based on the height of a different one. Although we tried to do this using the <a href="https://facebook.github.io/react/docs/component-specs.html">React lifecycle</a> methods, there ended up being too many edge cases and we were having to add more and more states just to avoid:</p>

<pre><code class="javascript">currentTemplateHeight=$('.panel-template-wrap').height();
$('.panel-data-items').css('padding-top', currentTemplateHeight);
</code></pre>

<p>In this case, we found it more straightforward to go with the jQuery solution.</p>

<h3>React == Refactor</h3>

<p>When we started out converting the app to React, it was hard to know whether or not an element should be its own component or if it could exist within another one. Often when we add new features, we have to refactor to make sure that we are reusing components and maintaining a single source of truth.</p>

<p>For example, we originally had one component to hold metadata on an artwork, such as artist, title, and date:
<code>javascript
var PanelArtworkInfo = React.createClass({
  ...
  render: function() {
    var artistName;
    var artworkTitle;
    var artworkDate;
    ...
    if (this.props.artwork.artist &amp;&amp; this.props.artwork.artist['name']) {
      artistName = &lt;ArtistName artwork={this.props.artwork} setTemplateArtistId={this.props.setTemplateArtistId} /&gt;;
    } else {
      artistName = &lt;span&gt;Unattributed&lt;/span&gt;;
    }
    artworkTitle = this.props.artwork.title ? this.props.artwork.title : 'Untitled';
    artworkDate = this.props.artwork.date ? this.props.artwork.date : 'No Date';
    ...
    return (
      &lt;div className="dummy-wrap"&gt;
        &lt;div className="row"&gt;
          ...
          &lt;div className="col-sm-6"&gt;
            &lt;div className="artist-name"&gt;
              {artistName}
            &lt;/div&gt;
            &lt;div className="title"&gt;
              {artworkTitle}
            &lt;/div&gt;
            &lt;div className="date"&gt;
              {artworkDate}
            &lt;/div&gt;
            ...
          &lt;/div&gt;
        &lt;/div&gt;
        ...
      &lt;/div&gt;
    );
  }
});
</code></p>

<p>When we implemented a new 'minimized' view for artworks, we also showed the title and artist, and so we broke these bits of information into separate components:
```javascript
var ArtistName = React.createClass({
  handleClick: function() {
    if (this.props.artwork.artist['name']) {
      this.props.setTemplateArtistId(this.props.artwork.artist['_id'])
    }
  },
  render: function() {
    var artistName;
    if (this.props.artwork.artist &amp;&amp; this.props.artwork.artist['name']) {
      artistName = <a className="artist-as-template-link"
                      data-template-id={this.props.artwork.artist['_id']}
                      onClick={this.handleClick}
                      data-template-type="Artist" href="#">
                    {this.props.artwork.artist['name']}
                  </a>;
    } else if (this.props.artwork['cultural_maker']) {
      artistName = <span>{this.props.artwork['cultural_maker']}</span>;
    } else {
      artistName = <span>Unattributed</span>;
    }
    return (
      <div className="artist-name">
        {artistName}
      </div>
    );
  }
});</p>

<p>var ArtworkTitle = React.createClass({
  render: function() {
    var artworkTitle = this.props.artwork.title ? this.props.artwork.title : 'Untitled';
    return (
      <div className="title">
        {artworkTitle}
      </div>
    );
  }
});</p>

<p>var ArtworkDate = React.createClass({
  render: function() {
    var artworkDate = this.props.artwork.date ? this.props.artwork.date : 'No Date';
    return (
      <div className="date">
        {artworkDate}
      </div>
    );
  }
});
```</p>

<p>And updated our parent to reuse the new child components:
<code>javascript
var PanelArtworkInfo = React.createClass({
  ...
  render: function() {
    ...
    return (
      &lt;div className="dummy-wrap"&gt;
        &lt;div className="row"&gt;
          ...
          &lt;div className="col-sm-6"&gt;
            &lt;ArtistName artwork={this.props.artwork} setTemplateArtistId={this.props.setTemplateArtistId} /&gt;
            &lt;ArtworkTitle artwork={this.props.artwork} /&gt;
            &lt;ArtworkDate artwork={this.props.artwork} /&gt;
            ...
          &lt;/div&gt;
        &lt;/div&gt;
        ...
      &lt;/div&gt;
    );
  }
});
</code></p>

<h3>Writing Specs</h3>

<p>All of the existing specs for the app were written in RSpec, so we chose to write integration tests using RSpec+Capybara. The headless Capybara webkit did not integrate with our React setup, so we switched to using Selenium as our Capybara JavaScript driver (which also conveniently let us debug our specs within the browser).</p>

<p>Our main challenge with specs had to do with RSpec not waiting long enough for components (such as autocomplete results) to appear, perhaps due to React's Virtual DOM. We spent many sad hours debugging spurious tests, and even included a few dreaded 'sleep' commands. Eventually, we integrated the <a href="https://github.com/y310/rspec-retry">rspec-retry</a> gem to retry spurious tests during CI.</p>

<h3>Conclusion</h3>

<p>Converting our app to use a React-based front-end went surprisingly smoothly. We were able to incrementally change certain templates to React components, which made it easy to test as we went along. Additionally, our development time in adding new features since then has decreased dramatically. It is much easier to add new components or edit existing ones when there is a single source of truth and you don't have to search through global event listeners.</p>

<p>Choosing a front-end framework is non-trivial but incredibly important, and we are glad we found React. Because it does not require much overhead and it is possible to only use it on a portion of a page, React can be integrated into small or large projects. Although we deliberated for a long time over whether or not to use a framework, we never regretted moving to React and investing in the future of the app.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[We open sourced our Isomorphic Javascript website]]></title>
    <link href="http://artsy.github.io/blog/2014/09/05/we-open-sourced-our-isomorphic-javascript-website/"/>
    <updated>2014-09-05T15:09:00+00:00</updated>
    <id>http://artsy.github.io/blog/2014/09/05/we-open-sourced-our-isomorphic-javascript-website</id>
    <content type="html"><![CDATA[<p><img src="/images/2014-09-05-we-open-sourced-our-isomorphic-javascript-website/force.png" alt="May The Force be With You" /></p>

<p>Today we're happy to announce we've open sourced the entire Artsy.net web app, <a href="https://github.com/artsy/force-public">Force</a>.</p>

<p>Over the past few months, we've rewritten our web front-end to move off Rails and on to a <a href="http://nodejs.org/">Node.js</a> stack that shares Javascript code and rendering between the server and client, otherwise known as <a href="http://nerds.airbnb.com/isomorphic-JavaScript-future-web-apps/">Isomorphic Javascript</a>. After migrating to this new stack, we open-sourced our boilerplate, <a href="http://ezeljs.com">Ezel</a>, and have now gone a step further and open sourced Artsy.net.</p>

<!-- more -->


<h2>Isomorphic vs Monolithic</h2>

<p>Our transition to an isomorphic Javascript stack has been very successful albeit with some speed bumps. If you're interested in the details we've written <a href="http://artsy.github.io/blog/2013/11/30/rendering-on-the-server-and-client-in-node-dot-js/">a blog post</a>, given a talk at <a href="https://www.joyent.com/developers/videos/node-js-on-the-road-nyc-craig-spaeth-brennan-moore">Node on the Road</a> (slides <a href="http://www.slideshare.net/craigspaeth/artsy-node-on-the-roady-slides">here</a>), and another more extensive talk at <a href="http://www.hakkalabs.co/articles/monolithic-to-distributed-how-artsy-transitioned-from-ruby-on-rails-to-node-js-and-isomorphic-javascript#">this meetup</a>.</p>

<p>The short story is that we moved from a monolithic rails app to a couple of Node servers on Heroku. This vastly improved the performance of our site and our own development speed. Using the patterns in Ezel, we are able to tailor assets packages to specific pages and render some of the page on the server. This cut our page-load in half (from 6.5 seconds to under 3 seconds) and our tests take about 5 minutes (down from around 5 hours!) with little reduction in coverage. Performance numbers aside, our real win was dramatically improved development speed due to some architecture decisions we made.</p>

<h2>Modularity</h2>

<p><a href="https://artsy.net/artwork/nathan-sawaya-red-head"><img src="/images/2014-09-05-we-open-sourced-our-isomorphic-javascript-website/sawaya.jpg" alt="Nathan Sawaya, Red Head, 2009" /></a></p>

<p>One of the biggest takeaways from the transition is the pleasure of modularity. By breaking our project up into smaller reusable pieces such as <a href="https://github.com/artsy/ezel#project-vs-apps-vs-components">apps &amp; components</a> we make it easier to experiment, test, and refactor with confidence knowing our code is encapsulated into clearly defined pieces.</p>

<p>For instance, we recently redesigned our <a href="https://artsy.net/about">about</a> page. To gradually introduce the new page, we simply started a new about2 app along side our old about app which you can see <a href="https://github.com/artsy/force-public/tree/0d5a49da08e94a91b3f23c7cd1005c1e83da7ba5/apps">a little back in Force's history</a>. This let us push code into the new about2 app with confidence it wasn't touching other parts of the stack. When it was time to ship it, we simply deleted the old about app folder and search and replaced "about2" to "about". There was no need to dig around various stylesheets, views, etc. folders looking for places where code for the old about page might still live.</p>

<p><a href="https://github.com/artsy/ezel#components">Components</a> are particularly useful for re-usability. For instance building <a href="https://artsy.net/gene/abstract-expressionism">this gene page</a> (source code <a href="https://github.com/artsy/force-public/tree/master/apps/gene">here</a>) was mostly a matter of pulling in various components like a <a href="https://github.com/artsy/force-public/tree/master/components/follow_button">follow button</a>, a <a href="https://github.com/artsy/force-public/tree/master/components/filter">filter</a> component, this <a href="https://github.com/artsy/force-public/tree/master/components/artist_fillwidth_list">artist fill-width layout</a>, etc. Because the CSS for those components are clearly self-contained it's easy to build up a small asset package that uses only the minimal CSS needed which you can see <a href="https://github.com/artsy/force-public/blob/master/assets/gene.styl">here</a>.</p>

<p>We're so convinced this encapsulation is important that we've updated Ezel to <a href="https://github.com/artsy/ezel/tree/master/src/js-example/apps/commits/public/images">use app/component-level public folders</a> by default so you can even modularize static assets, like images, and keep them coupled with their respective apps/components.</p>

<h2>Open Source by Default</h2>

<p><img src="/images/2014-09-05-we-open-sourced-our-isomorphic-javascript-website/octocat.jpg" alt="Ocotcat" /></p>

<p>Even though Force isn't a library, we have open-soured many of its components and libraries. Before open sourcing Force, we open sourced app-specific modules such as <a href="https://github.com/artsy/artsy-backbone-mixins">these backbone mixins</a> <a href="https://github.com/artsy/artsy-passport">this Artsy API authentication library</a>, or <a href="https://github.com/artsy/backbone-cache-sync">this module</a> we use to cache server-side Backbone requests.</p>

<p>Open-sourcing Force was pretty straightforward but we needed to make our sensitive keys/secrets private while not complicating development. To do this we wrote a .env file and uploaded it as a private gist that gets downloaded when setting up the app. We wanted to spread this open-source-by-default culture so we decided to update Ezel's configuration to be able to use a .env file in this way as well. This makes it easy keep your sensitive configuration data private while allowing the rest of your app code to be open source. You can read more about this in Ezel's <a href="https://github.com/artsy/ezel#build-scripts--configuration">Build Scripts &amp; Configuration docs</a>.</p>

<h2>Spreading The Love</h2>

<p>Force serves as an example of how we structured a large <a href="http://ezeljs.com">Ezel</a> project and contains the full commit history of its construction. Unfortunately, due to image licensing issues, we cannot open up the Artsy API and therefore this repository can't serve as a runnable clone of our website. However, we will continue to merge our production code into it. If you have any questions feel free to hit us up on twitter: <a href="https://twitter.com/craigspaeth">@craigspaeth</a>, <a href="https://twitter.com/dzucconi">@dzucconi</a>, <a href="https://twitter.com/zamiang">@zamiang</a>.</p>

<p>We're excited to continue pushing open source at Artsy. For more exciting open source projects take a look at <a href="https://github.com/artsy">our Github profile</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rendering on the Server and Client in Node.js]]></title>
    <link href="http://artsy.github.io/blog/2013/11/30/rendering-on-the-server-and-client-in-node-dot-js/"/>
    <updated>2013-11-30T22:38:00+00:00</updated>
    <id>http://artsy.github.io/blog/2013/11/30/rendering-on-the-server-and-client-in-node-dot-js</id>
    <content type="html"><![CDATA[<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/isomorphic.png" alt="Diagram of Shared Server/Client Architecture" /></p>

<p>At Artsy we've been building <a href="http://nodejs.org/">Node.js</a> applications that share code and rendering between the server and browser. We've seen many benefits from this -- pages load faster, we can optimize SEO, developers are more productive, and JavaScript coding is just an overall better experience.</p>

<p>Today we're happy to announce <a href="http://ezeljs.com/">Ezel</a>, our open source boilerplate we use to bootstrap our Node projects and the <a href="https://github.com/artsy/benv">various</a> <a href="https://github.com/artsy/backbone-super-sync">node</a> <a href="https://github.com/artsy/sharify">modules</a> that built up to it.</p>

<p>In his article, <a href="http://nerds.airbnb.com/isomorphic-JavaScript-future-web-apps/"><em>Isomorphic JavaScript: The Future of Web Apps</em></a>, Spike Brehm from AirBnB describes this growing trend well and we're excited to be a part of it. In this article I'll tell Artsy's story of moving from a single monolithic application to modular <a href="http://backbonejs.org/">Backbone</a> apps that run in Node and the browser and consume our external API.</p>

<!-- more -->


<h2>Growing Pains</h2>

<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/rails-evolution.png" alt="Evolution of Artsy SOA Diagramm" /></p>

<p>Artsy started as a mostly standard <a href="http://rubyonrails.org/">Rails</a> app almost three years ago. In these beginnings we were wildly productive and owe a lot of props to this great framework. However as time went on we started to deviate from the conventional Rails path until we were hardly leveraging much Rails at all. To support an early iOS app we used <a href="https://github.com/intridea/grape">Grape</a> to build an API. While building our API we wrote a lot of client-side JavaScript and soon integrated <a href="http://backbonejs.org/">Backbone</a> for organization. Eventually we cleanly separated our project into a single page Backbone app talking to our API all on inside of this original repository.</p>

<p>We knew we were outgrowing this monolithic project because we had some clear problems...</p>

<ul>
<li>Slow initial page loads because of lacking server-side rendering. Twitter <a href="https://blog.twitter.com/2012/improving-performance-twittercom">describes this problem well</a>.</li>
<li>Slow following client-side renders because of downloading large asset packages without clear ways to break them up.</li>
<li>SEO issues like building <a href="https://developers.google.com/webmasters/ajax-crawling/docs/specification">escaped fragment</a> pages in Ruby on the server while our users saw what JavaScript rendered on the client.</li>
<li>Maintaining duplicated Ruby/JavaScript code such as templates, date libraries, etc.</li>
<li>Very slow and brittle tests. We had a massive integration test suite consisting of over 3000 <a href="https://github.com/jnicklas/capybara">Capybara</a> tests that took hours to run because we lacked good JavaScript testing tools.</li>
<li>Poor mobile experience from trying to responsively scale down a large single page app with bloated and unused assets.</li>
<li>Slow asset compilation, server boot, and general build times. Productivity suffered greatly as more code was added to the same monolithic project.</li>
</ul>


<h2>There's Got to Be a Better Way</h2>

<p>A monolithic app that treats it's client-side code as a second class citizen was clearly not going to scale. Our poor mobile web experience was a good candidate to try something new. So we started building a separate mobile optimized website (m.artsy.net).</p>

<p>Some goals became clear:</p>

<ul>
<li>Better client-side tools from JavaScript testing to package managers.</li>
<li>Share rendering code server/client to reduce duplication and optimize initial page load.</li>
<li>Flexibility. We needed a way to divide our app into smaller chunks with smaller asset packages.</li>
</ul>


<h2>Choosing Technology</h2>

<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/tech.png" alt="Logos of Browserify, Express, and Backbone" /></p>

<p>Node was a clear choice because it made sharing rendering code server/client possible where other languages and frameworks struggle to do so. There were some existing Node projects that accomplish this such as <a href="http://derbyjs.com/">Derby</a> and <a href="https://github.com/airbnb/rendr">Rendr</a>. However, adopting these had challenges of their own including being difficult to integrate with our API, learning unnecessary conventions, or being early prototypes with lacking documentation.</p>

<p>We wanted an approach that breaks our app into smaller, more flexible, pieces. Not all of Artsy needs to be a thick-client app, or even use much client-side JavaScript at all. Adopting an existing solution and combining most of the server and client into a shared abstraction seemed like an unnecessary black box. After trying many other frameworks we found a combination of lower-level tools to be a clear winner.</p>

<p>We open sourced this combination of tools and patterns into <a href="http://ezeljs.com/">Ezel</a>. Ezel is a light-weight boilerplate project using <a href="http://expressjs.com/">Express</a> and <a href="http://backbonejs.org/">Backbone</a> for structure, and <a href="http://browserify.org/">Browserify</a> to compose modules that can be shared server/client.</p>

<h2>Sharing and Rendering Server/Client</h2>

<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/rendering.png" alt="Diagram of Server + Client Render" /></p>

<p>To share rendering code server/client we had to make sure our templates and objects being passed in to them could work the same server/client.</p>

<h3>Sharing Objects (Backbone Models)</h3>

<p><a href="http://browserify.org/">Browserify</a> lets you write modules that can run in Node or the browser. Since Backbone is able to be required on the server out of the box, it's easy to write models and collections that can be required on both sides with Browserify. However, there are two main speed bumps in doing this:</p>

<ol>
<li><p>Backbone uses AJAX for persistence.</p>

<p>We needed a Backbone.sync adapter that makes HTTP requests server-side, so we wrote one and <a href="https://github.com/artsy/backbone-super-sync">it's open sourced.</a></p></li>
<li><p>Data from the server needed to be shared in modules that are used server/client.</p>

<p>For instance, our API is an external URL stored in an environment variable. We needed to use this variable in a module that will be required on the server and the client with Browserify. <a href="http://backbonejs.org/#FAQ-bootstrap">Bootstrapping data</a> is a common technique to share data from the server by embedding JavaScript in the initial HTML and exposing that data globally to the client. To avoid exposing globals we open sourced a tiny module called <a href="https://github.com/artsy/sharify">sharify</a>.</p></li>
</ol>


<h3>Sharing Templates</h3>

<p>Browserify even lets you share non-JavaScript components server/client using <a href="https://github.com/substack/node-browserify#list-of-source-transforms">transforms</a>. To reuse our <a href="http://jade-lang.com/">jade</a> templates server/client it was a simple matter of using the <a href="https://github.com/OliverJAsh/node-jadeify2">jadeify</a> transform.</p>

<h3>All Together Now</h3>

<p>With templates and models require-able server/client, sharing rendering code became much simpler. Below is an example using the same artwork model and detail template server/client.</p>

<p>Shared Backbone "Artwork" model to be required server/client:</p>

<pre><code class="javascript models/artwork.js">var Backbone = require('backbone'),
    API_URL = require('sharify').data.API_URL;

module.exports = Artwork = Backbone.Model.extend({

  url: API_URL + '/api/v1/artwork'

});
</code></pre>

<p>Shared partial jade template used server/client:</p>

<pre><code class="jade templates/artwork-details.jade">h1= artwork.get('artist').name
h2= artwork.get('title')
</code></pre>

<p>Full server-side page template including the partial:</p>

<pre><code class="jade templates/artwork-page.jade">doctype 5
html
  head
    title Artsy | #{artwork.get('title')}
  body
    include artwork-details
    != sharify.script()
</code></pre>

<p>Route handler that uses the model server-side:</p>

<pre><code class="javascript app.js">//...
var Artwork = require('models/artwork.js');

app.get('/artwork/:id', function(req, res) {
  new Artwork({ id: req.params.id }).fetch({
    success: function(artwork) {
      // Boostrap artwork data into sharify
      res.locals.sharify.data.ARTWORK_JSON = artwork.toJSON();
      res.render('artwork-page', { artwork: artwork });
    }
  });
});
</code></pre>

<p>Client side code that requires the partial template and model:</p>

<pre><code class="javascript client.js">var Artwork = require('models/artwork.js'),
    ARTWORK_JSON = require('sharify').data.ARTWORK_JSON,
    detailsTemplate = require('templates/artwork-details.jade');

var artwork = new Artwork(ARTWORK_JSON);
artwork.on('change', function() {
  $('body').html(detailsTemplate({ artwork: artwork }));
});
</code></pre>

<h2>Developer Happiness</h2>

<p><img src="/images/2013-12-18-rendering-on-the-server-and-client-in-node-dot-js/so-much-win.png" alt="Happy Developer Image" /></p>

<p>Not only does sharing code server/client let you easily optimize page rendering for fast page loads, but development becomes a lot nicer because we can reuse server-side JavaScript tools including...</p>

<h3>Package Managers</h3>

<p>With Browserify we were able to use npm as a package manager for server or client-side dependencies. There are <a href="http://bower.io/">other</a> <a href="http://component.io/">package</a> <a href="http://jamjs.org/">managers</a> for the client-side. However, because we were already using npm (and npm supports git urls), we could usually point to the project hosted on npm or Github without having to fork it.</p>

<p>For projects that don't support CommonJS modules (or npm), often one can still use npm and requires like so:</p>

<pre><code class="json">"devDependencies": {
  "zepto": "git://github.com/madrobby/zepto.git#c074a94f0f26dc946f1c501f5f45d603adada44d"
}
</code></pre>

<pre><code class="javascript client.js">// Require the base Zepto library (attaches `Zepto` to window)
require('zepto/src/zepto.js');
// Attach Zepto's plugins
require('zepto/src/event.js');
require('zepto/src/detect.js');
// ....
</code></pre>

<h3>Testing</h3>

<p>Testing is light-years ahead because you can test all of your code in Node headless. I wrote <a href="/blog/2013/06/14/writing-headless-backbone-tests-with-node-dot-js/">an article</a> on this a while back, and now with Browserify it's even better.</p>

<p>Models, templates, and other modules that are shared server/client can be required into <a href="http://visionmedia.github.io/mocha/">mocha</a> and tested server-side without extra effort. For more view-like client-side code that depends on DOM APIs, pre-rendered HTML, etc., we open sourced a library called <a href="https://github.com/craigspaeth/benv">benv</a> to help build a fake browser environment in Node for testing.</p>

<h3>Modularity</h3>

<p>We wanted to avoid a monolithic organization that groups code by type such as "stylesheets", "javascripts", "controllers", etc.. Not only is this a maintenance problem as it makes boundaries of your app unclear, but it also affects your users because it encourages grouping assets into large monolithic packages that take a long time to download.</p>

<p>Instead, we borrowed a page from <a href="http://stackoverflow.com/questions/2472984/django-and-project-application-organization">Django</a> and broke up our project into smaller conceptual pieces called "apps" (small express sub-applications mounted into the main project) and "components" (portions of reusable UI such as a modal widget). This let us easily maintain decoupled segments of our project and build up smaller asset packages through Browserify's <code>require</code>s and <a href="http://learnboost.github.io/stylus/docs/import.html">Stylus</a>' <code>import</code>s. For more details on how this is done please check out <a href="http://ezeljs.com/">Ezel</a>, its <a href="https://github.com/artsy/ezel#project-vs-apps-vs-components">organization</a>, and <a href="https://github.com/artsy/ezel#asset-pipeline">asset pipeline</a> docs.</p>

<p>It's also worth noting, to avoid CSS spaghetti we followed a simple convention of name-spacing all of our classes/ids by the app or component name it was a part of. This was inspired by a <a href="http://philipwalton.com/articles/css-architecture/">blog post from Philip Walton</a>.</p>

<h2>Success!</h2>

<p>With this new architecture and set of Node tools we've seen enormous benefits compared to the pains of developing Backbone in a monolithic project with lacking JavaScript tools. Our mobile web experience is much better, we can render more content on the server for SEO and faster page loads, our test/build/deploy cycles went from hours to minutes, our developer on-boarding time went from days to minutes, and overall developer happiness has significantly improved.</p>

<p>It's an exciting time to be developing JavaScript apps and we will continue to open source our efforts wherever possible. Thanks and <a href="https://github.com/artsy">follow us on Github</a>!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Writing Headless Backbone Tests With Node.js]]></title>
    <link href="http://artsy.github.io/blog/2013/06/14/writing-headless-backbone-tests-with-node-dot-js/"/>
    <updated>2013-06-14T17:48:00+00:00</updated>
    <id>http://artsy.github.io/blog/2013/06/14/writing-headless-backbone-tests-with-node-dot-js</id>
    <content type="html"><![CDATA[<h2>TL;DR</h2>

<p>Write fast, headless, tests for Backbone using Node.js. See this project as an example  <a href="https://github.com/craigspaeth/backbone-headless-testing">https://github.com/craigspaeth/backbone-headless-testing</a>.</p>

<h2>A Brief History</h2>

<p>Artsy is mostly a thick client <a href="http://backbonejs.org/">Backbone</a> app that sits on <a href="http://rubyonrails.org/">Rails</a> and largely depends on <a href="http://jnicklas.github.io/capybara/">Capybara</a> (<a href="http://docs.seleniumhq.org/">Selenium</a> backed bot that clicks around Firefox) for testing it's javascript. This leads to some seriously brittle and slow integration tests. <a href="http://artsy.github.io/blog/2012/02/03/reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/">Despite being able to wrangle Capybara</a> to do most of our client-side testing, we knew there must be a better way.</p>

<p>When building a CMS app for our gallery partners to manage their Artsy inventory, we built a new Backbone app on top of <a href="http://nodejs.org/">node.js</a>. The result was a headless test suite that runs around 60 times faster.</p>

<p>Let's take a look at how it's done.</p>

<!-- more -->


<h2>Setting Up The Environment</h2>

<p>The trick to testing client-side code in node.js is creating an environment that mimics the browser. <a href="https://github.com/tmpvar/jsdom">Jsdom</a> does just that by bringing a pure javascript implementation of the DOM to node.js.</p>

<pre><code class="javascript">jsdom.env({
  html: "&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;",
  done: function(errs, window) {
    global.window = window;
    // ...
    callback();
  }
});
</code></pre>

<p>At this point we've globally exposed the <code>window</code> object of our jsdom browser. However the DOM isn't the only global dependency in most of our client-side code. We'll also need to expose our common libraries like Backbone, Underscore, and jQuery.</p>

<pre><code class="javascript">global.window = window;
global.Backbone = require('../app/javascripts/vendor/backbone.js');
global.Underscore = require('../app/javascripts/vendor/underscore.js');
global.jQuery = require('../app/javascripts/vendor/jQuery.js');
</code></pre>

<p>We can simply require Backbone, Underscore, and jQuery like any node module because they follow <a href="http://wiki.CommonJS.org/wiki/Modules/1.1.1">CommonJS</a> convention. However not all libraries are CommonJS compatible, and in this case you might have to expose their attachment to <code>window</code>.</p>

<pre><code class="javascript">global.window = window;
require('../app/javascripts/vendor/zepto.js');
global.Zepto = window.Zepto;
</code></pre>

<p>Finally you probably have a namespace like <code>App</code> which your components attach to.</p>

<pre><code class="javascript">global.window = window;
// Libraries
global.Backbone = require('../app/javascripts/vendor/backbone.js');
global.Underscore = require('../app/javascripts/vendor/underscore.js');
global.jQuery = require('../app/javascripts/vendor/jQuery.js');
// Namespace
global.App = {};
// We're ready to test some Backbone components
</code></pre>

<p>Try to keep global dependencies to a minimum. This reduces setup/teardown, increases modularity, and makes it easier to test your code.</p>

<p>For example, instead of attaching a view to <code>App</code> it might be better to pass that view in to the options of another so you can call <code>this.options.header.doSomething()</code>.</p>

<h2>Unit Testing Models</h2>

<p>Because all good javascript guides are based off Todo apps, let's pretend we're testing a Todo model.</p>

<pre><code class="javascript">App.Todo = Backbone.Models.extend({

  urlRoot: '/api/todo',

  complete: function() {
    var self = this;
    $.ajax({
      url: '/api/todos/' + this.get('id') + '/complete',
      type: 'PUT',
      success: function() { self.set({ completed: true }); }
    });
  }
});
</code></pre>

<p>Let's test that <code>#complete</code> makes the proper API PUT and <code>completed</code> is updated to true. After we setup our jsdom environment we need to stub <code>$.ajax</code> using <a href="http://sinonjs.org/docs/#stubs">sinon</a> as we won't be sending XHRs in node.</p>

<pre><code class="javascript">before(function(done) {
  jsdom.env({
    html: "&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;",
    done: function(errs, window) {
      global.$ = require('../../app/javascripts/vendor/jquery.js');
      //...
    }
  });
});

beforeEach(function(done) {
  ajaxStub = sinon.stub($, 'ajax');
  todo = new App.Todo({ title: 'Feed the cat', id: 'feed-the-cat' });
});
</code></pre>

<p>Now we can simply assert that <code>$.ajax</code> was called with the right params and completed changed.</p>

<pre><code class="javascript">it('PUTs to the API', function() {
  todo.complete();
  $.ajax.args[0][0].type.should.equal('PUT');
  $.ajax.args[0][0].url.should
    .equal('/api/todos/feed-the-cat/complete');
});

it('updates the item to be completed', function() {
  todo.set('completed', false);
  $.ajax.args[0][0].success();
  todo.get('completed').should.equal(true);
});
</code></pre>

<h2>Unit Testing Views</h2>

<p>Models are easy to unit test because they're mostly self-contained javascript. However a Backbone view might expect some server-side rendered HTML, use client-side templates, communicate to other views, and so on. This makes it harder to test but manageable given our set up.</p>

<p>Let's pretend we have a view that renders our todo list inside a server-side rendered element, and uses a client-side template to fill in the actual list items.</p>

<p>Our DOM might look something like this:</p>

<p>``` html</p>

<div id='todos'>
  <h1>Things I need to do today</h1>
  <ul class='todos-list'></ul>
</div>


<pre><code>
and our view might look something like this:
</code></pre>

<p>App.TodosListView = Backbone.View.extend({</p>

<p>  el: '#todos',</p>

<p>  template: JST['todos/list_items'],</p>

<p>  initialize: function() {
    this.collection.bind('add remove', this.render);
  },</p>

<p>  render: function() {
    this.$('.todos-list')
      .html(this.template({ todos: this.collection.models }));
  }
})
```</p>

<p>We can render the server-side <code>#todos</code> element by compiling the express view into html and injecting it straight in jsdom with our globally exposed jQuery.</p>

<pre><code class="javascript">filename = path.resolve(__dirname, '../app/views/index.jade');
template = fs.readFileSync(filename).toString();
html = jade.compile(template, { filename: filename })();
$('html').html(html);
</code></pre>

<p>Next we need to expose our client-side templates. In this case I'm assuming client-side templates are pre-compiled into functions namespaced under a global JST object like in the <a href="http://guides.rubyonrails.org/asset_pipeline.html">Rail's asset pipeline</a> (if you're looking for a node.js tool <a href="https://github.com/craigspaeth/nap">nap</a> is what Artsy uses).</p>

<p>We need to mimic what the JST functions are expecting so that when calling <code>JST['foo/bar']({ foo: 'some-data' })</code> we get back a string of html.</p>

<pre><code class="javascript">global.JST = {};
var filename = path.resolve(
  __dirname,
  '../app/javascripts/templates/todos/list.jade'
);
JST['todos/list'] = jade.compile(
  fs.readFileSync(filename).toString(),
  { filename: filename }
);
</code></pre>

<p>With our server-side HTML injected and our client-side templates ready to use, all that's needed is to require any other dependent Backbone components. This boilerplate can get pretty repetitive and would be good to wrap up into a helper.</p>

<pre><code class="javascript">var clientenv = require('../helpers/clientenv');

before(function(done) {
  clientenv.setup(function() {
    global.App.Todo = require('../app/javascripts/models/todo.js');
    global.App.Todos = require('../app/javascripts/collections/todos.js');
    done();
  });
});

beforeEach(function(done) {
  var templateFilename = path.resolve(
        __dirname,
        '../../views/index.jade'
      ),
      html = require('jade').compile(
        fs.readFileSync(templateFilename).toString(),
        { filename: templateFilename }
      )();
  $('html').html(html);
  view = new App.TodosListView();
  done();
});

it('renders items as they are added', function() {
  view.collection.add([
    new App.Todo({ title: 'clean the kitchen' })
  ]);
  view.$el.html().should.include('clean the kitchen');
});
</code></pre>

<p>With a little bit more work, testing views in node can be almost as easy as testing models.</p>

<h2>Integration Tests</h2>

<p>Although I encourage writing way more unit test coverage as they're faster and less brittle, it is necessary to have integration tests to cover longer scenarios. At Artsy we use some tricks to make integration testing less painful.</p>

<h3>Stubbing the API Layer</h3>

<p>In Artsy's case we're consuming a JSON API service that already has ample test coverage, so it makes sense to cut off integration at this point and stub our API responses.</p>

<p>To do this we can conditionally check which environment we're running in and swap out the API to use a real API or an <a href="http://expressjs.com/">express</a> app serving a stubbed API.</p>

<pre><code class="javascript">if(app.get('env') == 'test') {
  app.set('api url', 'http://localhost:5000');
  // Create a mock api server in your test helpers
  // and run it on 5000 in a before block
} else {
  app.set('api url', 'http://api.my-app.com');
}
// Bootstrap in your server-side view so the client app
// knows where to point
app.locals.API_URL_ROOT = app.get('api url');
</code></pre>

<p>If our API was hosted on the same server as our client app, or we're proxying API calls because of lack of <a href="http://en.wikipedia.org/wiki/Cross-Origin_Resource_Sharing">CORS</a> support, this could be as easy as swapping out middleware.</p>

<pre><code class="javascript">if(app.get('env') == 'test') {
  app.use('/api', require('./test/helpers/mock_api'));
} else {
  app.use('/api', require('./routes/api'));
}
</code></pre>

<p>This speeds up integration tests and simplifies the stack by not populating a database or booting an API server.</p>

<h3>Headless Integration Tests with Zombie.js</h3>

<p>Selenium has to actually boot up Firefox and poll the UI to wait for things to appear. This disconnect means extra seconds of "wait_util we're sure" time.  <a href="http://zombie.labnotes.org/">Zombie.js</a> is backed by our friend jsdom and alleviates these issues by giving us a fast headless browser that we can programmatically access.</p>

<p>Of course the caveat to headless testing is that you can't visually see how a test is actually failing. Using <code>{ debug: true }</code> in your options will spit every Zombie action to stdout. In most cases this is enough, but sometimes you need to go a step further and actually visualize what the test is doing.</p>

<p>A trick we use is to write tests using the browser's <code>jQuery</code>. This is more familiar than Zombie's DSL and lets you copy and paste test code directly in your browser's console to see if it's actually doing what you want.</p>

<p>.e.g</p>

<pre><code class="javascript">Browser.visit('http://localhost:5000', function(err, browser) {
  var $ = browser.window.$;

  // From here we can run `NODE_ENV=test node app.js` and copy
  // this code right into our browser's console.
  $('#add-todo').val('Foo').change();
  });
}
</code></pre>

<h2>Conclusion</h2>

<p>Using these techniques has greatly increased productivity and developer happiness for testing client-side code. For an example implementation of this see <a href="https://github.com/craigspaeth/backbone-headless-testing">https://github.com/craigspaeth/backbone-headless-testing</a>.</p>

<p>Looking forward, testing client-side code can be made even better by using a package manager that adds require functionality like <a href="https://github.com/substack/node-browserify">browserify</a>, <a href="https://github.com/component/component">component</a>, or <a href="http://requirejs.org/">require.js</a>. But I've gone far enough for now, maybe in another blog post (leave a comment if you're interested).</p>
]]></content>
  </entry>
  
</feed>
