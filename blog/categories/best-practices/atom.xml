<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: best practices | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/best-practices/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2018-10-20T18:00:11+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A History of Artsy's Web Frontend]]></title>
    <link href="http://artsy.github.io/blog/2018/10/04/artsy-frontend-history/"/>
    <updated>2018-10-04T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/10/04/artsy-frontend-history</id>
    <content type="html"><![CDATA[<p>As Artsy Engineering grows in 2018, we have so many newcomers looking for context: they want to understand the
systems they'll be working in day-to-day. Awesome! But it's not enough to understand the systems themselves, it's
often helpful to understand the <em>history</em> of how we ended up where we are.</p>

<p>Frontend web development has changed a <em>lot</em> during Artsy's existence, and it continues to advance at a blistering
pace. It's easy to get caught up in the churn of frameworks and languages and tools, so I want to use this post as
an opportunity to contextualize each transition that Artsy's web presence has made over the past seven years. We've
changed technologies, but we've tried to do so with care and attention. Documenting these decisions is important
(and is ideally done <a href="https://ashfurrow.com/blog/contemporaneous-blogging/">contemporaneously</a>), but even with the best documentation, <a href="https://github.com/artsy/artsy.github.io/pull/489#discussion_r221301472">sometimes our own documentation
is unclear to us</a>.</p>

<p>In an effort to help contextualize our web frontend (which is <a href="https://github.com/artsy/force">open source</a>), this blog post will document
the major transitions that Artsy's web presence has made over the past seven years. Let's begin!</p>

<!-- more -->


<a name="Backbone...CoffeeScript"></a>
<h2>Backbone + CoffeeScript</h2>

<p>Artsy as you know it today began as a standard Rails application. We ran <code>git init</code> in January 2011, which coupled
our backend API to our web frontend, but since our frontend was just a fancy user interface for our API, this
worked for over two years. The web app itself was a kind of simplified MVC – controller logic lived inside the
views and models dealt with backend communication and notifying the view of state changes. For CSS, we used the
SASS CSS preprocessor. The Rails backend served initial pages that were then populated with follow-up API calls
made on the client-side. At a <em>very</em> high level, this isn't <em>that</em> different from what we do today with React.</p>

<p>Our site was built with a framework called <a href="http://backbonejs.org">Backbone</a>, which was really well-suited for our needs at the time.
From their documentation:</p>

<blockquote><p>Philosophically, Backbone is an attempt to discover the minimal set of data-structuring (models and collections)
and user interface (views and URLs) primitives that are generally useful when building web applications with
JavaScript. In an ecosystem where overarching, decides-everything-for-you frameworks are commonplace, and many
libraries require your site to be reorganized to suit their look, feel, and default behavior — Backbone should
continue to be a tool that gives you the <em>freedom</em> to design the full experience of your web application.</p></blockquote>

<p>As an outsider to the web at that time, I can't comment too heavily on Backbone. It seems like the freedom
(emphasis theirs) that they describe is a freedom from tangled jQuery code everywhere. I think our definition of
freedom on the web frontend has evolved since then, but that's just my feeling.</p>

<p>The other key component to our web frontend was <a href="https://coffeescript.org">CoffeeScript</a>. According to its documentation, "CoffeeScript is
a little language that compiles into JavaScript", which was pretty important at the time. JavaScript in 2011 was
very different from JavaScript today. The CoffeeScript docs also state that "JavaScript has always had a gorgeous
heart", which I'm not sure I'd agree with to be honest, but the CoffeeScript project really shows how a handful of
engineers working to improve something they care about can change an entire industry. While I don't think
contemporary JavaScript would have gotten as good as it has without CoffeeScript, it's a bit anachronistic to see
it used today.</p>

<p>Our goal as a (very small!) engineering team at the time was to keep our moving parts to a minimum.
Rails+SASS+CoffeeScript+Backbone helped us achieve that goal, and we couldn't have gotten this far without the help
of those projects.</p>

<a name="Ezel..amp..Friends"></a>
<h2>Ezel &amp; Friends</h2>

<p>In November 2013, we split our web frontend from the API backend. You can read
<a href="2013_review">all the details in this blog post</a>, but the story is summarized nicely as "moving from a single
monolithic application to modular Backbone apps that run in Node and the browser and consume our external API."
This move from monolith to modular systems continues to influence day-to-day work on the Artsy Engineering team.</p>

<p>We had already started moving away from a typical Rails app by moving our API to <a href="https://github.com/ruby-grape/grape">Grape</a> in order to support an
iOS application. The monolith also had some clear drawbacks including severe page load times, maintaining
duplicated backend and frontend UI templates, slow test suites, and poor developer productivity. We took the
project of building our mobile web frontend, m.artsy.net (still known as "martsy" internally) as an opportunity to
address these problems.</p>

<p>We built our new site with <a href="https://github.com/ruby-grape/grape">Node.js</a> since it allowed us to share and consolidate our server/client rendering
code. We split out areas of concern into separate "apps", with their own bundled CSS/JS to help page load times. We
server-side rendered above-the-fold content and used client-side JS to load the rest, which helped SEO and user
experience. We took a <a href="http://getbem.com/introduction/">BEM</a>-like approach to our CSS, which helped developer productivity. Our technical
decisions were driven primarily by our desire to create great user experiences.</p>

<p>And because we are an open source by default organization, we collected these approaches into an open source
project called <a href="https://github.com/artsy/ezel">Ezel</a>. While our main app used this Ezel approach, other new web apps – CMS systems for our
partners, auction-management systems for our admins, etc – were built on new internal tools to share assets and
code across the apps. We experimented a lot; we got pretty good at sharing resources across codebases. Most of our
web projects started on Heroku before moving to heavier-duty deployments as needed. Our frontend mindset at the
time (2015) was focused on getting to a stable, predictable stack. However... we started experimenting with React
around the same time.</p>

<p>CoffeeScript and Backbone were still working for us, and we still use them in production in many systems. However,
the state of the art in web development moved on. When I joined the auctions team and helped maintain one of our
CoffeeScript+Backbone apps, I was <em>very</em> confused about how data flowed from one part of the app to another, across
languages, with a lot of magic happening. I think that's typical in these kinds of apps – "convention over
configuration" is a good mantra <em>if</em> you can expect that incoming engineers are familiar with the conventions.
That's just not the case anymore.</p>

<p>By 2016, we had <a href="http://artsy.github.io/blog/2015/04/08/creating-a-dynamic-single-page-app-for-our-genome-team-using-react/">experimented with React</a> and followed up with <a href="http://artsy.github.io/blog/2016/08/09/the-tech-behind-live-auction-integration/">another app built with the
technology</a>. React (and Redux) were very well-suited for our realtime auction bidding UI, and would later
prove helpful in our <a href="https://github.com/artsy/positron">editorial CMS</a>. These experiences helped prove the technology was ready for
production use <em>and</em> convinced us that React was great at reducing the complexities of building user interfaces
(the realtime nature of our auctions product was particularly well-suited for Redux's state management; it was our
first from-scratch React app).</p>

<p>When the Artsy business require us to make changes to how we build software, like splitting up our monolith, we try
to take full advantage of those changes to improve how we work, which means evaluating new tools. Adopting Node.js
and Ezel wouldn't make sense today, but at the time, they helped us scale up Artsy's business without the same
scaling up of our engineering resources. Ezel helped us do more with less, which is still an important criteria we
use for evaluating new tools.</p>

<a name="React"></a>
<h2>React</h2>

<p>By 2017, the divisions between our mobile frontend and web frontend teams had been totally dissolved (as they
should – the division between mobile and web developers is a false dichotomy). Our <a href="http://artsy.github.io/blog/2017/04/14/artsy-technology-stack-2017/">2017 tech stack
post</a> discusses this in depth, but our goal was really to unify the paradigm that frontend engineers
at Artsy use to build user interfaces, whether that's on mobile or web. React and React Native were our answer to
that challenge.</p>

<p>On the web side of things, however, Artsy had another challenge. Sure, React is great, and sure, it's how we want
to build user interfaces, but how do we get there? We're not fans of large rewriting projects, so we opted for what
we call an "incremental revolution" approach. We built a library called <a href="https://github.com/artsy/stitch">Stitch</a> that would let us mount React
components inside our existing app. Using this approach, we could migrate to React component-by-component. We've
been using Stitch in production for over a year and have been very happy with its approach; you can read more
details of integrating it into our main frontend app <a href="http://artsy.github.io/blog/2017/09/05/Modernizing-Force/">in this blog post</a>.</p>

<p>Today, principal React work takes place in <a href="https://github.com/artsy/reaction">a shared components repo</a>. We share these components across
several of our web apps using Stitch. We have been pretty pleased with the results! But our dive into React is only
just beginning. The community is moving quickly to figure out what best practices make sense in the React paradigm,
and we're a part of that. We are evaluating technologies like <a href="https://www.styled-components.com">styled-components</a> and <a href="https://jxnblk.com/styled-system/">styled-system</a> to create
a universal design system within Artsy. The area is under very active development, so I'll save details for a
future blog post.</p>

<p>I can't go too much further without talking about GraphQL. v1 of our API (REST) is still in use around much of
Artsy and, despite the best efforts of some of our engineers, v2 of our API (<a href="http://stateless.co/hal_specification.html">HAL</a>) hasn't gained significant
internal use yet. Instead, we found ourselves building a <a href="https://graphql.org">GraphQL</a> server to orchestrate API calls to our
existing APIs. This confers many benefits, which I describe from a mobile perspective in some detail <a href="https://ashfurrow.com/blog/the-spirit-of-moya/">here</a>.
The key thing to understand about our GraphQL server, <a href="https://github.com/artsy/metaphysics/">which is open source</a>, is that it is under the
stewardship of our frontend engineers, not our platform engineers. That's not to say that our platform team isn't
involved with its development – in fact, they've been key to scaling it up – but Artsy frontend engineers created
the server to help us build better UIs, and while the technology is still very new, we continue to see it pay
dividends.</p>

<p>Okay so remember earlier when I said that we dissolved our mobile team? Well, I was on that team and it wasn't like
our mobile engineers all learned how Artsy does web – we brought our culture and tools with us and, together with
our web colleagues, have built an integrated engineering team that's greater than the sum of its parts. One thing
that was important to mobile engineers was type safety, so we had to have a conversation about JavaScript.</p>

<p>On its own, JavaScript can't guarantee type safety. We investigated two options: <a href="http://www.typescriptlang.org">TypeScript</a> and <a href="https://flow.org">Flow</a>. <a href="http://artsy.github.io/blog/2017/02/05/Front-end-JavaScript-at-Artsy-2017/">This
blog post</a> goes into detail about our decision, but tl;dr we chose TypeScript. We have been building (and
helping to build) tools <a href="https://github.com/relay-tools/relay-compiler-language-typescript">relay-compiler-language-typescript</a> to take full advantage of interoperability
between TypeScript types and GraphQL types through <a href="https://facebook.github.io/relay/">Relay</a>, as well as using Babel 7 to migrate existing projects
to TypeScript incrementally, which you can read about in more detail <a href="https://artsy.github.io/blog/2017/11/27/Babel-7-and-TypeScript/">here</a>. It's all very exciting – you
can read more on how Relay and GraphQL interoperate <a href="http://artsy.github.io/blog/2018/07/25/Relay-Networking-Deep-Dive/">in this blog post</a>.</p>

<p>We started building software in React not because it was trendy, but because it helped our engineering team deliver
more value to the business. It's been a huge success, but not without its costs. We've tried to mitigate those
costs by using tools like Stitch to migrate apps to React incrementally, and through spreading knowledge of how our
stack through internal knowledge-sharing like <a href="http://artsy.github.io/series/javascriptures/">JavaScriptures</a>. While the transition to React has had its costs,
<em>not</em> moving would also be costly, too.</p>

<hr />

<p>Since I joined Artsy, I've seen us continually investing in tooling that helps us build better software. The
results of this culture-of-continuous-improvement speak for themselves: with fewer than 30 engineers total, we
support a growing company with a suite of software built for many canvasses <em>and</em> we have an outsized impact on the
software industry relative to our size. Our frontend web stack is just one facet of our evolving technology –
there's lots of exciting stuff on the backend, too (<a href="https://github.com/artsy/hokusai">for example...</a>). Through my research for this blog
post, I learned a lot about what drives technological decisions on our team. From humble beginnings as a Rails app,
to CoffeeScript and Bootstrap, to React and GraphQL, Artsy Engineering has evolved our frontend software to achieve
a quality worthy of art – both from the user's perspective and from the developer's. I'm very excited about what's
coming next, and I can't wait to share it with you. Have a great day!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My First Week On Call]]></title>
    <link href="http://artsy.github.io/blog/2018/05/30/my-first-week-on-call/"/>
    <updated>2018-05-30T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/05/30/my-first-week-on-call</id>
    <content type="html"><![CDATA[<p>As I write this, I have completed my first ever engineering on-call rotation at Artsy, so naturally I had to write a blog post about some of the things I learned.</p>

<!-- more -->


<p>A year ago, I would have been terrified to be one of two engineers responsible for handling everything from re-sending automated emails to fixing total site outages, but <a href="https://ashfurrow.com/blog/perspective-of-the-polyglot/">I have grown a lot</a> so being on-call was only <em>regular</em>-level intimidating. And indeed, with supportive documentation and a good partner, I didn't experience any situations where I felt truly lost about what to do next.</p>

<p>But I did learn a few things. So let's discuss a few things that weren't immediately obvious to me.</p>

<a name="Ignore.My.Instinct.to.Fix.Things.Right.Away"></a>
<h2>Ignore My Instinct to Fix Things Right Away</h2>

<p>This sounds really counterintuitive, right? I mean, a server is down, let's reboot it so it's up again! It's got a little red X next to it in AWS, let's make it a green checkmark again! I want that checkmark!</p>

<p>But that's not always the best course of action. Sometimes, fixing something right away would deprive us of the opportunity to figure out <em>why</em> it broke in the first place. For example: we had Rails servers running out of disk space, and rebooting those servers would have refreshed their drives and fixed the problem, but one of our platform engineers asked me to wait so they could ssh in and examine the contents of the filesystems. In the mean time, the load balancer had already routed traffic around the servers, so there was no need to rush to fix anything.</p>

<p>My instinct to fix things right away was at odds with the team's desire to understand why something broke.</p>

<a name="What.is.an.Incident..Even."></a>
<h2>What is an Incident, Even?</h2>

<p>One thing became really clear to be, really quickly: people have many different, valid perspectives on what an "incident" is. Our support documentation goes into detail about what our responsibilities as on-call engineers are responsible for, and what should be routed through product teams to be prioritized, but my support partner and I still hit cases where we weren't quite sure if we should take action.</p>

<p>Sometimes, issues of critical importance were brought to our #incidents Slack channel, but weren't <em>really</em> incidents, from an Engineering perspective. We erred on the side of helping our colleagues, but it's difficult. I want to help people! But I also have responsibilities. Balancing the two is a skill every engineer has to develop, and being on-call highlighted the importance of balance in a new way for me.</p>

<p>My first ever jobs were retail, where I helped rural Canadians learn to use their first ever cell phones, and IT helpdesks; both taught me how to handle support requests in a way that makes the other person feel like things are going to be okay. I had to reapply those skills when on-call because sometimes what people were bringing to my attention fell outside the scope of an "incident". Consider the response:</p>

<blockquote><p>What you've reported isn't an incident, talk to your PM.</p></blockquote>

<p>... and contrast it with:</p>

<blockquote><p>This falls outside the scope of immediate support, so I've opened a ticket for you. You can talk to the team PM about prioritization.</p></blockquote>

<p>This kind of reply also aligns with Artsy's <a href="https://github.com/artsy/meta/blob/master/meta/what_is_artsy.md#artsy-values">values</a> of <strong>Positive Energy</strong> and <strong>People are Paramount</strong>. Everyone working at Artsy is here to make art a bigger part of culture, and that shared understanding helped.</p>

<a name="We.Need.to.Improve.our.Automated.Alerts"></a>
<h2>We Need to Improve our Automated Alerts</h2>

<p>For a few months now, Artsy Engineering has been discussing how to consolidate our automated alerts. I somehow got it in my head that anything in our #alerts channel needed immediate engineer attention, when in fact, our #alerts channel is often noisy. By the final day of my rotation, I learned that not everything needed immediate attention.</p>

<p>That's a bit of a problem. There are alerts that need immediate intervention ("the API servers are all down") and there are alerts that need no intervention ("this server is responding slowly, oh wait, it's back to normal, never mind"), and then there are the tricky ones: the ones that need <em>eventual</em> intervention ("gosh, our image processing API out of disk space for the third time in a month, we need to look into that"). Figuring out how to sort mid-level, important-but-not-urgent automated alerts from critical ones will be a critical part of our long-term support process.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fully Automated Standups]]></title>
    <link href="http://artsy.github.io/blog/2018/05/07/fully-automated-standups/"/>
    <updated>2018-05-07T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/05/07/fully-automated-standups</id>
    <content type="html"><![CDATA[<p>When I began working at Artsy four years ago, remotely, I really didn't like the weekly engineering standup. I'd sit in front of my computer and strain to hear a dozen people gathered around a laptop with Google Hangout. They'd discuss implementation details for projects I wasn't familiar with, and then I'd do the same to them (our mobile team was still very separate from our web team). Twenty minutes would pass and I didn't feel like my work experience at Artsy had been enriched in any way.</p>

<p>The first time I came to New York to visit the office – before moving here – I sat down with <a href="https://github.com/dylanfareed">Dylan</a> and <a href="https://github.com/orta">Orta</a>. Dylan ran the weekly standup, and Orta was also not a fan of the meeting. Dylan was clear: if the standup wasn't working for the two of us, then it wasn't working for anyone. So let's fix it together.</p>

<!-- more -->


<p>And we did. We installed new sound-baffling ceiling tiles to help remote workers hear the boardroom more clearly. We restructured updates, moving from individual updates to team updates. We introduced a section for people to ask and offer help. All kinds of changes. I started looking forward to standup.</p>

<p>At Artsy, when you see something that could be improved about the way that we work, you are expected to help improve it. Dylan taught me that lesson, and I still take it to heart.</p>

<p>Last summer, I started taking on more responsibilities for the Artsy Engineering team, including running the weekly standup meeting. It was previously run by a single engineer, <a href="https://github.com/craigspaeth">Craig</a>, who was juggling a lot of team-wide responsibilities. I was happy to help him out and run the meeting, but I had only replaced <em>myself</em> as a single-point-of-failure for standup; even with Orta running things sometimes, the process itself was still as brittle as when Craig was running things alone. After a few months, Orta and I decided to fix things.</p>

<p>Our goal: fully automated standups. No single person should ever be a point-of-failure for our team. We moved through a few distinct steps.</p>

<p>First, we had to document the process of running the standup. This was crucial: standups should be run as a function of the documentation, so that any engineer at Artsy can run an effective standup. The docs should not only help the engineer run the meeting, but help them feel <em>capable</em> of running the meeting. And once documentation is in place, anyone can help improve the docs (and consequently, improve the process). The current <a href="https://github.com/artsy/meta/blob/master/meta/open_standup.md">docs are open source</a>.</p>

<p>Next, we had to get other engineers running the meeting. We split up the responsibilities of the meeting into two roles: a talking part, and a note-taking part. Both are integral, and different people gravitate towards differently roles. Splitting things up not only made running the meeting easier, but it made running the meeting more appealing to newcomers.</p>

<p>Once the meeting was a two-person responsibility, we started bringing on other engineers to help. I would ask around to see who was interested in helping running a meeting, giving choice of role to the other person. After each meeting, I'd ask the person about how we could improve the docs. Each week, the docs got better and better.</p>

<p>The next phase was moving to having standup run entirely by other engineers. I had a list of engineers who had never run a standup, and worked down the list to get as many engineers having run a meeting as possible. I made <a href="https://github.com/artsy/meta/pull/21">this pull request</a> making it clear that running the standup meeting is a responsibility that every member of the team <em>shares</em>.</p>

<p>Eventually, I felt we were ready to move to a self-perpetuating standup. At the end of each standup, we would solicit volunteers to run next week's meeting. Fully-automated standups! We'd done it! Things were working, though we did recently decide to <a href="https://github.com/artsy/meta/pull/32">integrate the standup schedule into our new support on-call schedule</a>; the engineers beginning their rotation were responsible for running the standup. This eliminated the kind of awkward "okay who wants to do this next week?" part of our meeting.</p>

<p>At each step, we improved the process. Through effective documentation and positive energy, we reduced the <a href="https://en.wikipedia.org/wiki/Bus_factor">bus factor</a> for our engineering team's management. And more importantly, I think, we made it clear to every Artsy engineer that managing our team and improving how we work is a responsibility we have, together.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Programmer Misconceptions about Art]]></title>
    <link href="http://artsy.github.io/blog/2018/04/18/programmer-misconceptions-about-art/"/>
    <updated>2018-04-18T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/04/18/programmer-misconceptions-about-art</id>
    <content type="html"><![CDATA[<p>Our mission at Artsy has been to make a world where everyone is moved by art every day, and at a high level, the way that our engineering team supports that mission is through building software. We have built systems and databases and user interfaces that represent different facets of the art world, and throughout our work, we have... made some mistakes.</p>

<p>That's okay! Programmers make mistakes all the time. There is <a href="https://github.com/kdeldycke/awesome-falsehood">a large list of blog posts</a> describing various programmer misconceptions, from subjects you might expect would be simple to model in computers, like units of measurement and time, to subjects that are based more in the human condition, like postal addresses and marriage.</p>

<p>In the interest of openness and sharing what we've learned, the Artsy Engineering team has come up with the following list of misconceptions programmers believe about art. Thank you to everyone at Artsy who contributed to this list.</p>

<!-- more -->


<ul>
<li>All artworks have an artist (some artworks are attributed to "cultural makers", others have a manufacturer).</li>
<li>All artworks have exactly one artist (some artworks are collaborations).</li>
<li>All artworks are unique (there are editions, reproductions, and series of works, and modeling the relationships between them all is nontrivial).</li>
<li>All lots in an art auction are artworks (some lots are "experiential", like a visit to an artist's studio).</li>
<li>Only rich people buy art.</li>
<li>Only rich people can afford to buy art, and everyone else just buys posters of "real" art.</li>
<li>All artworks have a title (some are untitled).</li>
<li>"Untitled" signifies an artwork has no title (some artworks are titled "Untitled").</li>
<li>All artwork titles can fit inside 512 characters (not true, <a href="https://www.artsy.net/artwork/matt-goerzen-sockpuppet-theatre-representing-the-techniques-tools-and-environments-whereby-hackers-and-other-info-warriors-might-seek-to-parse-through-elsewhere-distorted-informational-domains-to-make-sense-of-them-and-also-possibly-to-acquire-by-illicit-or-clever-means-good-information-that-can-then-be-communicated-in-a-way-that-sheds-light-on-deceptions-but-can-also-be-difficult-to-evaluate-on-their-own-terms-due-to-the-elite-requisites-of-interpreting-such-knowledge-or-more-generalized-uncertaintities-regarding">here is a counterexample</a>).</li>
<li>An artwork is associated with a natural, canonical category.</li>
<li>An artwork belongs to only one gallery/collector/auction house at a time (provenance of artworks is complicated, and there is no canonical source of truth).</li>
<li>Art should always be rendered at its maximum size (there are complex business constraints and art world norms that need to be considered).</li>
<li>People buy art mostly for its visual qualities (most people buy art because of a story, because they understand what the artwork is trying to say, or because they simply can't stop thinking about it).</li>
<li>People don't buy art from JPEGs (in fact, people buy art that hasn't even been created yet).</li>
<li>"My kid can paint that" (<a href="https://twitter.com/ashfurrow/status/707273704640798720">but did they?</a>).</li>
<li>The art market needs technology because it's inefficient (the art market needs technology because technology can help expand the entire art world).</li>
<li>Intermediaries in the art market are bad (eg. galleries: they enable artists to make works for years before they sell anything, they are the enabler, not the obstacle).</li>
<li>There is one "art world" (there are thousands of galleries around the world, specializing in everything from contemporary jewelry and emerging conceptual art to Chinese scroll painting and regional landscapes).</li>
<li>Your opinion on art doesn't matter, the industry will independently determine value of an artwork (everyone has opinions, your appreciation of art is <em>all</em> about <em>you</em>).</li>
<li>The art world is hermetic and isn't relevant to my life (in fact the arts contribute billions of dollars to the economy, employ thousands of people, have a ripple effect on urban life, and are often a major source of inspiration for the TV, movies, and books we all consume on a daily basis).</li>
<li>Gallerists are fancy people in a luxury business, living fancy lives (in fact, the average salary for a gallery owner is way lower than you think).</li>
<li>Art and engineering are orthogonal (nope, just look at us!).</li>
</ul>


<p>Do you have expertise in an area programmers often get wrong? Write a blog post and add it to <a href="https://github.com/kdeldycke/awesome-falsehood">the list of misconceptions</a>!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Write Great Outage Post-Mortems]]></title>
    <link href="http://artsy.github.io/blog/2014/11/19/how-to-write-great-outage-post-mortems/"/>
    <updated>2014-11-19T12:21:00+00:00</updated>
    <id>http://artsy.github.io/blog/2014/11/19/how-to-write-great-outage-post-mortems</id>
    <content type="html"><![CDATA[<p>The website is finally back up after crashing hard for 4 hours straight.</p>

<p>Recently AWS decided to <a href="http://aws.amazon.com/blogs/aws/ec2-maintenance-update">reboot a few of your servers for a critical update</a>. It didn't seem like it was going to be a big deal, except that the schedule was only accommodating if you were in the Pacific Northwest. The first reboot took out a secondary replica of our MongoDB database. Unfortunately <a href="https://github.com/mongoid/moped/issues/321">the driver handled that poorly</a> and spent the first 400ms of every subsequent HTTP request trying to reconnect to the missing instance. That server came back up, but failed to find its storage volumes because of a human mistake in a past migration and the alerts were mistakenly silenced by someone monitoring the system. A few hours later the primary was being stepped down and rebooted, sending the driver into panic over <a href="https://github.com/mongoid/moped/issues/323">another bug</a>. The site went down.</p>

<p>None of this was obvious while it was happening as the rate of automated alerts grew. Engineers communicated to the team that they are actively focusing on bringing the systems back up. This helped to fend off a large amount of instant messages, e-mails, texts and phone calls from various people on the team that were in the middle of demoing something to a very important prospective customer on the other side of the planet. It was also the middle of the night in New York.</p>

<p>Now that all the systems are back up, lets write a detailed outage post-mortem.</p>

<!-- more -->


<a name="Whose.Job.is.It."></a>
<h2>Whose Job is It?</h2>

<p>In a small or medium-sized company, the most senior engineering manager, CTO, VP or Head of Engineering should be writing an outage post-mortem. It's their job and responsibility to acknowledge, understand and explain what happened. Focusing attention away from the individual contributors allows the team to learn from the mistakes and address the root causes in time without the unnecessary stress or pressure during a crisis.</p>

<a name="Recipients"></a>
<h2>Recipients</h2>

<p>The post-mortem audience includes customers, direct reports, peers, the company's executive team and often investors. The e-mail may be published on your website, and otherwise goes to the entire team. It's critical to bcc everyone. This is the equivalent of a locked thread, avoiding washing the laundry in public: one of the worst possible things to see is when a senior manager replies back pointing an individual who made a mistake, definitely not an email you want accidentally sent to the entire company.</p>

<p>I usually begin my e-mails with <em>Team (on the bcc), ...</em>.</p>

<p>I also bcc myself and label the e-mail "Outages", to be able to easily find the incident history next time around.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/header.png" alt="header" /></p>

<a name="Outage.Email.Subject"></a>
<h2>Outage Email Subject</h2>

<p>Post-mortem subjects should include a date and a duration. This gets right to the point and offers a summary of the impact.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/subject.png" alt="subject" /></p>

<a name="Outage.Summary"></a>
<h2>Outage Summary</h2>

<p>The outage e-mail begins with a summary, a slightly expanded version of the subject line. Many people won't read the details, so include graphs. These should tell the same story as the description of the outage. I use <a href="http://newrelic.com">NewRelic's</a>.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/summary.png" alt="summary" /></p>

<a name="What.Caused.the.Outage"></a>
<h2>What Caused the Outage</h2>

<p>Explain what caused the outage on a timeline. Every incident begins with a specific trigger at a specific time, which often causes some unexpected behavior. For example, our servers were rebooted and we expected them to come back up intact, which didn't happen. Furthermore, every incident has a root cause: the reboot itself was trigger, however a bug in the driver caused the actual outage. Finally, there're consequences to every incident, the most obvious one is that the site goes down.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/cause.png" alt="cause" /></p>

<a name="How.was.the.Outage.Resolved"></a>
<h2>How was the Outage Resolved</h2>

<p>Now that the timeline of the outage is established, we explain what actions took place to resolve it.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/resolution.png" alt="resolution" /></p>

<a name="The.Post-Mortem"></a>
<h2>The Post-Mortem</h2>

<p>The post-mortem answers the single most important question of what could have prevented the outage.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/post-mortem.png" alt="post-mortem" /></p>

<a name="Outage.History"></a>
<h2>Outage History</h2>

<p>To most humans that encounter bugs, it may seem like your systems have failures all the time. It's important to educate everyone that an outage is much more than a bug and that it hopefully doesn't happen frequently. Provide a history of outages, referencing the last one.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/history.png" alt="history" /></p>

<a name="Don.t.Bury.It"></a>
<h2>Don't Bury It</h2>

<p>A few final words. Despite how painful an outage may have been, the worst thing you can do is to bury it and never properly close the incident in a clear and transparent way. Most humans come together in times of crisis and communication around outage post-mortems, in my experience, has always been met with positive energy, understanding comments, constructive suggestions and numerous offers to help.</p>
]]></content>
  </entry>
  
</feed>
